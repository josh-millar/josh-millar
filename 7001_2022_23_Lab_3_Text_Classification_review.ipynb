{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/josh-millar/josh-millar/blob/main/7001_2022_23_Lab_3_Text_Classification_review.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hExKCzh6doIW",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# Lab 3 - Neural Network Classifier Using Simple Word Embeddings\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HixoFOoCIJ7V",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "In this session, we demonstrate how to solve a text classification task using different neural classifiers. We will also experiment with different ways to use word embeddings for classification.\n",
        "\n",
        "We will use IMDB Large Movie Review Dataset to train a binary classification model, able to predict whether a review is positive or negative. First, our network takes one-hot word vectors as input, averages them to make one vector and trains a \n",
        "fully-connected layer to predict the output. In the second part, we replace the one-hot vectors with different word embeddings and add a layer to see how much that improves the performance. We will finally use CNNs to address the problem.\n",
        "\n",
        "We are going to use Keras Sequential API in this session. The Sequential API allows you to build models layer-by-layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8fpBfhBpupy",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "import tensorflow.keras as tk\n",
        "import numpy as np\n",
        "from keras.layers import Lambda, GlobalAveragePooling1D, Dense, Embedding\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.utils import pad_sequences\n",
        "\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqvPQvgvPv1W",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Downloading data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EundMtGPpCdf",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "The dataset we will be using is the IMDB Large Movie Review Dataset, which consists of 50,000 labeled movie reviews. These are split into 25,000 reviews for training and 25,000 reviews for testing. The  dataset contains an even number of positive and negative reviews, so randomly guessing yields 50% accuracy. The data is preprocessed. For text classification, we usually limit the size of the vocabulary to stop the data from becoming too sparse, creating possible overfitting. We hence keep the top 10,000 most frequently occurring words in the training data.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyuSzkafqNca",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "imdb = tk.datasets.imdb\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=10000)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6U4iCV9-rmay",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "We now can start look into the data, letâ€™s first see the length:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-gjWRAuqg5s",
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e21fb3b6-fdda-457e-f9f2-6d854a864e35"
      },
      "source": [
        "print(\"Training entries: {}, labels: {}\".format(len(X_train), len(y_train)))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training entries: 25000, labels: 25000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTRZrpcyr-4x",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "The  reviews have been converted to integers and each integer represents a  word in a dictionary. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79Ev72Kgq4XL",
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "415e9b8f-9ff7-4e11-a3ab-f69bf51dac53"
      },
      "source": [
        " X_train[0][:10]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tvuu4KhStqei",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "We can convert integers back to words by querying a dictionary object that contains the integer to string mapping:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMCH1OoDrSNR",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "word_index = imdb.get_word_index()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IreFXgruZot",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "Index 1 represents the beginning of the sentence and the index 2 is assigned to all unknown tokens. Index 0 will be used for padding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abIb7Fe5u3GQ",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "word_index = {k:(v+3) for k,v in word_index.items()}\n",
        "word_index[\"<PAD>\"] = 0\n",
        "word_index[\"<START>\"] = 1\n",
        "word_index[\"<UNK>\"] = 2  \n",
        "word_index[\"<UNUSED>\"] = 3"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9TnnSuspvC5b",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "To reverse key and values in a dictionary:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKOiVVXQu-_I",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmTJEm8xvUvW",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "To view a word:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqN5jgVKvJJZ",
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "9ca82522-bfac-4772-a235-d543ec6ce462"
      },
      "source": [
        "reverse_word_index[25]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'you'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6QjrzgVvrYn",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "And to recreate the whole sentence from our training data we define decode_review:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvrKeMgxvWlv",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "def decode_review(text):\n",
        "    return ' '.join([reverse_word_index.get(i, '?') for i in text])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sxg4YA_NvdRg",
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "outputId": "586d75e3-9827-40ef-b1bb-9b4a2ef1a3b1"
      },
      "source": [
        "decode_review(X_train[10])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"<START> french horror cinema has seen something of a revival over the last couple of years with great films such as inside and <UNK> romance <UNK> on to the scene <UNK> <UNK> the revival just slightly but stands head and shoulders over most modern horror titles and is surely one of the best french horror films ever made <UNK> was obviously shot on a low budget but this is made up for in far more ways than one by the originality of the film and this in turn is <UNK> by the excellent writing and acting that ensure the film is a winner the plot focuses on two main ideas prison and black magic the central character is a man named <UNK> sent to prison for fraud he is put in a cell with three others the quietly insane <UNK> body building <UNK> marcus and his retarded boyfriend daisy after a short while in the cell together they stumble upon a hiding place in the wall that contains an old <UNK> after <UNK> part of it they soon realise its magical powers and realise they may be able to use it to break through the prison walls br br black magic is a very interesting topic and i'm actually quite surprised that there aren't more films based on it as there's so much scope for things to do with it it's fair to say that <UNK> makes the best of it's <UNK> as despite it's <UNK> the film never actually feels restrained and manages to flow well throughout director eric <UNK> provides a great atmosphere for the film the fact that most of it takes place inside the central prison cell <UNK> that the film feels very claustrophobic and this immensely benefits the central idea of the prisoners wanting to use magic to break out of the cell it's very easy to get behind them it's often said that the unknown is the thing that really <UNK> people and this film proves that as the director <UNK> that we can never really be sure of exactly what is round the corner and this helps to ensure that <UNK> actually does manage to be quite frightening the film is memorable for a lot of reasons outside the central plot the characters are all very interesting in their own way and the fact that the book itself almost takes on its own character is very well done anyone worried that the film won't deliver by the end won't be disappointed either as the ending both makes sense and manages to be quite horrifying overall <UNK> is a truly great horror film and one of the best of the decade highly recommended viewing\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8gIzXncfaJK",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Creating One-hot word vectors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9W4yb3rv_E0",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "It is  common to use one-hot representation as input in NLP tasks. In Keras, the Embedding layer takes an index as an input and convert it to one-hot vector with the length of the vocabulary size. Then it multiplies these vectors by the embedding matrix to get relevant vectors. But there is no way to get a one-hot vector as the output of a layer in Keras. To solve this we use the Lambda() layer and a function that creates the one-hot layer. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPO_pK9zH4C5",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "def OneHot(input_dim=None, input_length=None):\n",
        "    \n",
        "    if input_dim is None or input_length is None:\n",
        "        raise TypeError(\"input_dim or input_length is not set\")\n",
        "\n",
        "    \n",
        "    def _one_hot(x, num_classes):\n",
        "        return K.one_hot(K.cast(x, 'uint8'),\n",
        "                          num_classes=num_classes)\n",
        "\n",
        "    return Lambda(_one_hot,\n",
        "                  arguments={'num_classes': input_dim},\n",
        "                  input_shape=(input_length,))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "364d3MAw0ez9",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "input_dim refers to the length of the one-hot vector and input_length refers to the length of the input sequence. Since the input to K.one_hot should be an integer tensor, we cast x to int (Keras passes around float tensors by default).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHz76GNA2M4r",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "In most cases, each text sequence has a different length in words. Hence, we fill sequences with a pad token (0) accordingly. This special token is then masked not to be accounted for in averaging, loss calculation etc. We set the maximum length to 256."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9G_o7PsvgSFt",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Preparing input data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiFn7sd_wF5j",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "VOCAB_SIZE = 10000\n",
        "MAX_SEQUENCE_LENGTH = 256\n",
        "\n",
        "X_train_enc = pad_sequences(X_train, value=word_index[\"<PAD>\"],\n",
        "                                                        padding='post',\n",
        "                                                        maxlen=256)\n",
        "\n",
        "X_test_enc = pad_sequences(X_test, value=word_index[\"<PAD>\"],\n",
        "                                                       padding='post',\n",
        "                                                       maxlen=256)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcjFH1wKF_7d",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "And to view a padded review:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwH4dcfW_a18",
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2c55a24-d5f9-460d-da56-26e4f1ce21e0"
      },
      "source": [
        "print(X_train_enc[1])\n",
        "print('\\nLength: ',len(X_train_enc))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[   1  194 1153  194 8255   78  228    5    6 1463 4369 5012  134   26\n",
            "    4  715    8  118 1634   14  394   20   13  119  954  189  102    5\n",
            "  207  110 3103   21   14   69  188    8   30   23    7    4  249  126\n",
            "   93    4  114    9 2300 1523    5  647    4  116    9   35 8163    4\n",
            "  229    9  340 1322    4  118    9    4  130 4901   19    4 1002    5\n",
            "   89   29  952   46   37    4  455    9   45   43   38 1543 1905  398\n",
            "    4 1649   26 6853    5  163   11 3215    2    4 1153    9  194  775\n",
            "    7 8255    2  349 2637  148  605    2 8003   15  123  125   68    2\n",
            " 6853   15  349  165 4362   98    5    4  228    9   43    2 1157   15\n",
            "  299  120    5  120  174   11  220  175  136   50    9 4373  228 8255\n",
            "    5    2  656  245 2350    5    4 9837  131  152  491   18    2   32\n",
            " 7464 1212   14    9    6  371   78   22  625   64 1382    9    8  168\n",
            "  145   23    4 1690   15   16    4 1355    5   28    6   52  154  462\n",
            "   33   89   78  285   16  145   95    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0]\n",
            "\n",
            "Length:  25000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1zcxFwNGepA",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "Now we will build our neural network model. We  are going to have a hidden layer with 16 hidden units. \n",
        "\n",
        "First, we want to transform each index to an embedded vector and then average all vectors to a single one. It has been shown that such an unweighted average of word vectors outperforms more complex networks (http://anthology.aclweb.org/P/P15/P15-1162.pdf)\n",
        "\n",
        "To average we need to ignore padded zeros:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yi04MLIvJOGZ",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "class GlobalAveragePooling1DMasked(GlobalAveragePooling1D):\n",
        "    def call(self, x, mask=None):\n",
        "        if mask != None:\n",
        "            return K.sum(x, axis=1) / K.sum(mask, axis=1)\n",
        "        else:\n",
        "            return super().call(x)\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whgIIB5ggjna",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "#Model 1: Neural network model using one-hot vectors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlOLnlnSJgrU",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "The first layer is a one-hot layer. The second layer computes average of all word vectors in a sentence without considering padding. The output vector is then piped through a fully-connected layer. The last layer has a single output node with the sigmoid activation function. The final value is a float between 0 and 1. At the end we visualize the model summary."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Input\n",
        "from keras.models import Model"
      ],
      "metadata": {
        "id": "ZEEnxaRd7cGU"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Pn83gBbxiK7",
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b74bd61b-7403-406a-de15-4c8e5327fbf9"
      },
      "source": [
        "input_layer = Input((MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
        "one_hot_layer = OneHot(input_dim=VOCAB_SIZE, input_length=MAX_SEQUENCE_LENGTH)(input_layer)\n",
        "averaging_layer = GlobalAveragePooling1DMasked()(one_hot_layer)\n",
        "hidden_layer = Dense(16)(averaging_layer)\n",
        "output = Dense(1, activation=\"sigmoid\")(hidden_layer)\n",
        "model = Model(inputs=[input_layer], outputs=[output])\n",
        "model.summary()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 256)]             0         \n",
            "                                                                 \n",
            " lambda (Lambda)             (None, 256, 10000)        0         \n",
            "                                                                 \n",
            " global_average_pooling1d_ma  (None, 10000)            0         \n",
            " sked (GlobalAveragePooling1                                     \n",
            " DMasked)                                                        \n",
            "                                                                 \n",
            " dense (Dense)               (None, 16)                160016    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 160,033\n",
            "Trainable params: 160,033\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Mz96xpCgvTj",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Training the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3HbW_IKLqwT",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "To compile the model we need a loss function and an optimizer. We use the binary_crossentropy loss function. We also use the Adam optimizer. You can read more about it here: https://arxiv.org/abs/1412.6980v8.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qh1PWTNMxjUw",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1jwQQqCN5Ia",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "When training, we want to check the accuracy of the model on the unseen data. So we create a validation set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5lAqzQlxjSM",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "X_val = np.array(X_train_enc[:10000])\n",
        "partial_X_train = np.array(X_train_enc[10000:])\n",
        "\n",
        "y_val = np.array(y_train[:10000])\n",
        "partial_y_train = np.array(y_train[10000:])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8Kpo5G3OJEY",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "Then we start to train the model for 40 epochs in mini-batches of 512 samples and monitor the model's loss and accuracy on the validation set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99_z39KAxjPi",
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c703970c-1659-431b-8132-32dd125b1ad3"
      },
      "source": [
        "history = model.fit(partial_X_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=40,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(X_val, y_val),\n",
        "                    verbose=1)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "30/30 [==============================] - 8s 101ms/step - loss: 0.6924 - accuracy: 0.5027 - val_loss: 0.6915 - val_accuracy: 0.5720\n",
            "Epoch 2/40\n",
            "30/30 [==============================] - 3s 94ms/step - loss: 0.6903 - accuracy: 0.6644 - val_loss: 0.6893 - val_accuracy: 0.6519\n",
            "Epoch 3/40\n",
            "30/30 [==============================] - 3s 96ms/step - loss: 0.6875 - accuracy: 0.6729 - val_loss: 0.6864 - val_accuracy: 0.6629\n",
            "Epoch 4/40\n",
            "30/30 [==============================] - 3s 101ms/step - loss: 0.6841 - accuracy: 0.6655 - val_loss: 0.6830 - val_accuracy: 0.6527\n",
            "Epoch 5/40\n",
            "30/30 [==============================] - 3s 95ms/step - loss: 0.6800 - accuracy: 0.6733 - val_loss: 0.6786 - val_accuracy: 0.6705\n",
            "Epoch 6/40\n",
            "30/30 [==============================] - 3s 101ms/step - loss: 0.6753 - accuracy: 0.6763 - val_loss: 0.6738 - val_accuracy: 0.6692\n",
            "Epoch 7/40\n",
            "30/30 [==============================] - 3s 106ms/step - loss: 0.6701 - accuracy: 0.6785 - val_loss: 0.6686 - val_accuracy: 0.6742\n",
            "Epoch 8/40\n",
            "30/30 [==============================] - 3s 98ms/step - loss: 0.6642 - accuracy: 0.6847 - val_loss: 0.6634 - val_accuracy: 0.6789\n",
            "Epoch 9/40\n",
            "30/30 [==============================] - 3s 96ms/step - loss: 0.6583 - accuracy: 0.6869 - val_loss: 0.6574 - val_accuracy: 0.6825\n",
            "Epoch 10/40\n",
            "30/30 [==============================] - 3s 102ms/step - loss: 0.6520 - accuracy: 0.6878 - val_loss: 0.6515 - val_accuracy: 0.6830\n",
            "Epoch 11/40\n",
            "30/30 [==============================] - 3s 104ms/step - loss: 0.6457 - accuracy: 0.6901 - val_loss: 0.6455 - val_accuracy: 0.6845\n",
            "Epoch 12/40\n",
            "30/30 [==============================] - 3s 103ms/step - loss: 0.6393 - accuracy: 0.6925 - val_loss: 0.6396 - val_accuracy: 0.6902\n",
            "Epoch 13/40\n",
            "30/30 [==============================] - 3s 102ms/step - loss: 0.6328 - accuracy: 0.6957 - val_loss: 0.6335 - val_accuracy: 0.6886\n",
            "Epoch 14/40\n",
            "30/30 [==============================] - 3s 98ms/step - loss: 0.6268 - accuracy: 0.6969 - val_loss: 0.6277 - val_accuracy: 0.6964\n",
            "Epoch 15/40\n",
            "30/30 [==============================] - 3s 99ms/step - loss: 0.6204 - accuracy: 0.7032 - val_loss: 0.6218 - val_accuracy: 0.6954\n",
            "Epoch 16/40\n",
            "30/30 [==============================] - 3s 102ms/step - loss: 0.6146 - accuracy: 0.7035 - val_loss: 0.6164 - val_accuracy: 0.6972\n",
            "Epoch 17/40\n",
            "30/30 [==============================] - 3s 97ms/step - loss: 0.6087 - accuracy: 0.7066 - val_loss: 0.6109 - val_accuracy: 0.7032\n",
            "Epoch 18/40\n",
            "30/30 [==============================] - 3s 105ms/step - loss: 0.6028 - accuracy: 0.7121 - val_loss: 0.6058 - val_accuracy: 0.7106\n",
            "Epoch 19/40\n",
            "30/30 [==============================] - 3s 103ms/step - loss: 0.5974 - accuracy: 0.7141 - val_loss: 0.6004 - val_accuracy: 0.7110\n",
            "Epoch 20/40\n",
            "30/30 [==============================] - 3s 96ms/step - loss: 0.5921 - accuracy: 0.7169 - val_loss: 0.5958 - val_accuracy: 0.7164\n",
            "Epoch 21/40\n",
            "30/30 [==============================] - 3s 95ms/step - loss: 0.5870 - accuracy: 0.7216 - val_loss: 0.5907 - val_accuracy: 0.7120\n",
            "Epoch 22/40\n",
            "30/30 [==============================] - 3s 95ms/step - loss: 0.5820 - accuracy: 0.7221 - val_loss: 0.5863 - val_accuracy: 0.7211\n",
            "Epoch 23/40\n",
            "30/30 [==============================] - 3s 102ms/step - loss: 0.5773 - accuracy: 0.7236 - val_loss: 0.5818 - val_accuracy: 0.7230\n",
            "Epoch 24/40\n",
            "30/30 [==============================] - 3s 95ms/step - loss: 0.5730 - accuracy: 0.7276 - val_loss: 0.5779 - val_accuracy: 0.7247\n",
            "Epoch 25/40\n",
            "30/30 [==============================] - 3s 95ms/step - loss: 0.5685 - accuracy: 0.7281 - val_loss: 0.5746 - val_accuracy: 0.7236\n",
            "Epoch 26/40\n",
            "30/30 [==============================] - 3s 95ms/step - loss: 0.5646 - accuracy: 0.7318 - val_loss: 0.5697 - val_accuracy: 0.7267\n",
            "Epoch 27/40\n",
            "30/30 [==============================] - 3s 105ms/step - loss: 0.5607 - accuracy: 0.7328 - val_loss: 0.5660 - val_accuracy: 0.7280\n",
            "Epoch 28/40\n",
            "30/30 [==============================] - 3s 101ms/step - loss: 0.5570 - accuracy: 0.7362 - val_loss: 0.5630 - val_accuracy: 0.7310\n",
            "Epoch 29/40\n",
            "30/30 [==============================] - 3s 95ms/step - loss: 0.5537 - accuracy: 0.7371 - val_loss: 0.5595 - val_accuracy: 0.7323\n",
            "Epoch 30/40\n",
            "30/30 [==============================] - 3s 101ms/step - loss: 0.5507 - accuracy: 0.7381 - val_loss: 0.5564 - val_accuracy: 0.7345\n",
            "Epoch 31/40\n",
            "30/30 [==============================] - 3s 101ms/step - loss: 0.5470 - accuracy: 0.7421 - val_loss: 0.5549 - val_accuracy: 0.7319\n",
            "Epoch 32/40\n",
            "30/30 [==============================] - 3s 96ms/step - loss: 0.5448 - accuracy: 0.7418 - val_loss: 0.5510 - val_accuracy: 0.7376\n",
            "Epoch 33/40\n",
            "30/30 [==============================] - 3s 95ms/step - loss: 0.5416 - accuracy: 0.7439 - val_loss: 0.5482 - val_accuracy: 0.7383\n",
            "Epoch 34/40\n",
            "30/30 [==============================] - 3s 101ms/step - loss: 0.5390 - accuracy: 0.7445 - val_loss: 0.5459 - val_accuracy: 0.7405\n",
            "Epoch 35/40\n",
            "30/30 [==============================] - 3s 102ms/step - loss: 0.5367 - accuracy: 0.7446 - val_loss: 0.5438 - val_accuracy: 0.7415\n",
            "Epoch 36/40\n",
            "30/30 [==============================] - 3s 102ms/step - loss: 0.5344 - accuracy: 0.7471 - val_loss: 0.5416 - val_accuracy: 0.7431\n",
            "Epoch 37/40\n",
            "30/30 [==============================] - 3s 95ms/step - loss: 0.5322 - accuracy: 0.7476 - val_loss: 0.5397 - val_accuracy: 0.7432\n",
            "Epoch 38/40\n",
            "30/30 [==============================] - 3s 95ms/step - loss: 0.5304 - accuracy: 0.7484 - val_loss: 0.5378 - val_accuracy: 0.7449\n",
            "Epoch 39/40\n",
            "30/30 [==============================] - 3s 101ms/step - loss: 0.5285 - accuracy: 0.7491 - val_loss: 0.5366 - val_accuracy: 0.7436\n",
            "Epoch 40/40\n",
            "30/30 [==============================] - 3s 98ms/step - loss: 0.5272 - accuracy: 0.7471 - val_loss: 0.5348 - val_accuracy: 0.7452\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_9a_rybhG5J",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Evaluating the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYLH8kOgOo9W",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "To evaluate the model on test data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFMt2Q7b3taP",
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d66476a-9918-4512-86fb-fff01edf65c9"
      },
      "source": [
        "results = model.evaluate(X_test_enc, y_test)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 4s 5ms/step - loss: 0.5351 - accuracy: 0.7414\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RrKiPHcAmQU",
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6a0350d-bc08-41b1-8388-2745d3575db1"
      },
      "source": [
        "print(results)\n",
        "# loss, accuracay "
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.535101592540741, 0.7414000034332275]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pW7IpHxMO6qp",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "Our first model accuracy using one-hot vectors is ~68%\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwZk_yoWhPJB",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Plotting the accuracy graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIDPH1J7PMzN",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "To plot accuracy and loss over epochs we can use Matplotlib:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install plot_keras_history\n",
        "from keras.utils import vis_utils\n",
        "from plot_keras_history import plot_history\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AaiPqegRDw-Y",
        "outputId": "ab27b2de-7c4f-42fd-9cfd-cd3ea11d61e4"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: plot_keras_history in /usr/local/lib/python3.9/dist-packages (1.1.38)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from plot_keras_history) (1.3.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from plot_keras_history) (1.10.1)\n",
            "Requirement already satisfied: support-developer>=1.0.2 in /usr/local/lib/python3.9/dist-packages (from plot_keras_history) (1.0.5)\n",
            "Requirement already satisfied: sanitize-ml-labels>=1.0.48 in /usr/local/lib/python3.9/dist-packages (from plot_keras_history) (1.0.50)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from plot_keras_history) (3.5.3)\n",
            "Requirement already satisfied: compress-json in /usr/local/lib/python3.9/dist-packages (from sanitize-ml-labels>=1.0.48->plot_keras_history) (1.0.8)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->plot_keras_history) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->plot_keras_history) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->plot_keras_history) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->plot_keras_history) (4.39.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->plot_keras_history) (8.4.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->plot_keras_history) (23.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib->plot_keras_history) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from matplotlib->plot_keras_history) (1.22.4)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.9/dist-packages (from pandas->plot_keras_history) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib->plot_keras_history) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LS9k2vvSAqB7",
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "9c057b11-ed19-4d73-e3e9-54d990ed0e5c"
      },
      "source": [
        "plot_history(history.history)\n",
        "plt.show()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7OwOQw4h8RX",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "#Model 2: Neural averaging model using an embedding layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-QzOMO_P4jc",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "Now instead of one-hot vectors, we want to use embeddings. We change our first layer in model1 to an Embedding layer. This layer takes the integer-encoded vocabulary and looks up the embedding vector for each word index. These vectors are learned as the model trains. The vectors add a dimension to the output array. The resulting dimensions are: (batch, sequence, embedding)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import GlobalAveragePooling2D"
      ],
      "metadata": {
        "id": "uJJ7YEa642r4"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFrCsL-NBFVL",
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0442cbe-c769-4a6d-cbc6-f7fb592159be"
      },
      "source": [
        "EMBEDDING_SIZE = 100\n",
        "\n",
        "input_layer = Input((MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
        "embed_layer = Embedding(\n",
        "    VOCAB_SIZE,\n",
        "    EMBEDDING_SIZE,\n",
        "    name=\"embedding\",\n",
        "    embeddings_initializer=\"glorot_uniform\",\n",
        "    input_length=MAX_SEQUENCE_LENGTH,\n",
        "    # mask_zero=True,\n",
        ")(input_layer)\n",
        "averaging_layer = GlobalAveragePooling1DMasked()(embed_layer)\n",
        "hidden_layer = Dense(16)(averaging_layer)\n",
        "output = Dense(1, activation=\"sigmoid\")(hidden_layer)\n",
        "model2 = Model(inputs=[input_layer], outputs=[output])\n",
        "model2.summary()\n",
        "model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 256)]             0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 256, 100)          1000000   \n",
            "                                                                 \n",
            " global_average_pooling1d_ma  (None, 100)              0         \n",
            " sked_1 (GlobalAveragePoolin                                     \n",
            " g1DMasked)                                                      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 16)                1616      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,001,633\n",
            "Trainable params: 1,001,633\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history2 = model2.fit(partial_X_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=40,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(X_val, y_val),\n",
        "                    verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5EpInyLQp6r",
        "outputId": "c5f1b657-4059-44c8-e3df-f526502b9844"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "30/30 [==============================] - 7s 171ms/step - loss: 0.6881 - accuracy: 0.6303 - val_loss: 0.6794 - val_accuracy: 0.7179\n",
            "Epoch 2/40\n",
            "30/30 [==============================] - 7s 219ms/step - loss: 0.6590 - accuracy: 0.7442 - val_loss: 0.6348 - val_accuracy: 0.7403\n",
            "Epoch 3/40\n",
            "30/30 [==============================] - 7s 221ms/step - loss: 0.5934 - accuracy: 0.7654 - val_loss: 0.5595 - val_accuracy: 0.7771\n",
            "Epoch 4/40\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.5044 - accuracy: 0.8129 - val_loss: 0.4798 - val_accuracy: 0.8047\n",
            "Epoch 5/40\n",
            "30/30 [==============================] - 4s 137ms/step - loss: 0.4193 - accuracy: 0.8491 - val_loss: 0.4109 - val_accuracy: 0.8432\n",
            "Epoch 6/40\n",
            "30/30 [==============================] - 3s 113ms/step - loss: 0.3529 - accuracy: 0.8774 - val_loss: 0.3647 - val_accuracy: 0.8594\n",
            "Epoch 7/40\n",
            "30/30 [==============================] - 2s 77ms/step - loss: 0.3057 - accuracy: 0.8915 - val_loss: 0.3359 - val_accuracy: 0.8699\n",
            "Epoch 8/40\n",
            "30/30 [==============================] - 3s 99ms/step - loss: 0.2707 - accuracy: 0.9027 - val_loss: 0.3172 - val_accuracy: 0.8754\n",
            "Epoch 9/40\n",
            "30/30 [==============================] - 3s 94ms/step - loss: 0.2428 - accuracy: 0.9141 - val_loss: 0.3049 - val_accuracy: 0.8794\n",
            "Epoch 10/40\n",
            "30/30 [==============================] - 1s 50ms/step - loss: 0.2204 - accuracy: 0.9229 - val_loss: 0.3017 - val_accuracy: 0.8780\n",
            "Epoch 11/40\n",
            "30/30 [==============================] - 2s 68ms/step - loss: 0.2013 - accuracy: 0.9307 - val_loss: 0.2933 - val_accuracy: 0.8817\n",
            "Epoch 12/40\n",
            "30/30 [==============================] - 2s 66ms/step - loss: 0.1824 - accuracy: 0.9383 - val_loss: 0.2892 - val_accuracy: 0.8825\n",
            "Epoch 13/40\n",
            "30/30 [==============================] - 1s 51ms/step - loss: 0.1670 - accuracy: 0.9445 - val_loss: 0.2880 - val_accuracy: 0.8848\n",
            "Epoch 14/40\n",
            "30/30 [==============================] - 1s 25ms/step - loss: 0.1532 - accuracy: 0.9511 - val_loss: 0.2911 - val_accuracy: 0.8848\n",
            "Epoch 15/40\n",
            "30/30 [==============================] - 2s 79ms/step - loss: 0.1407 - accuracy: 0.9565 - val_loss: 0.2918 - val_accuracy: 0.8846\n",
            "Epoch 16/40\n",
            "30/30 [==============================] - 1s 33ms/step - loss: 0.1297 - accuracy: 0.9610 - val_loss: 0.2958 - val_accuracy: 0.8840\n",
            "Epoch 17/40\n",
            "30/30 [==============================] - 1s 42ms/step - loss: 0.1191 - accuracy: 0.9654 - val_loss: 0.3005 - val_accuracy: 0.8843\n",
            "Epoch 18/40\n",
            "30/30 [==============================] - 1s 40ms/step - loss: 0.1101 - accuracy: 0.9681 - val_loss: 0.3064 - val_accuracy: 0.8833\n",
            "Epoch 19/40\n",
            "30/30 [==============================] - 1s 31ms/step - loss: 0.1013 - accuracy: 0.9720 - val_loss: 0.3134 - val_accuracy: 0.8823\n",
            "Epoch 20/40\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.0939 - accuracy: 0.9744 - val_loss: 0.3204 - val_accuracy: 0.8818\n",
            "Epoch 21/40\n",
            "30/30 [==============================] - 1s 41ms/step - loss: 0.0854 - accuracy: 0.9775 - val_loss: 0.3292 - val_accuracy: 0.8803\n",
            "Epoch 22/40\n",
            "30/30 [==============================] - 2s 61ms/step - loss: 0.0785 - accuracy: 0.9805 - val_loss: 0.3394 - val_accuracy: 0.8785\n",
            "Epoch 23/40\n",
            "30/30 [==============================] - 1s 19ms/step - loss: 0.0727 - accuracy: 0.9825 - val_loss: 0.3482 - val_accuracy: 0.8778\n",
            "Epoch 24/40\n",
            "30/30 [==============================] - 1s 29ms/step - loss: 0.0667 - accuracy: 0.9848 - val_loss: 0.3583 - val_accuracy: 0.8778\n",
            "Epoch 25/40\n",
            "30/30 [==============================] - 1s 35ms/step - loss: 0.0613 - accuracy: 0.9865 - val_loss: 0.3685 - val_accuracy: 0.8782\n",
            "Epoch 26/40\n",
            "30/30 [==============================] - 2s 60ms/step - loss: 0.0564 - accuracy: 0.9888 - val_loss: 0.3808 - val_accuracy: 0.8741\n",
            "Epoch 27/40\n",
            "30/30 [==============================] - 1s 46ms/step - loss: 0.0518 - accuracy: 0.9902 - val_loss: 0.3924 - val_accuracy: 0.8759\n",
            "Epoch 28/40\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.0475 - accuracy: 0.9916 - val_loss: 0.4049 - val_accuracy: 0.8730\n",
            "Epoch 29/40\n",
            "30/30 [==============================] - 1s 41ms/step - loss: 0.0435 - accuracy: 0.9922 - val_loss: 0.4156 - val_accuracy: 0.8740\n",
            "Epoch 30/40\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.0404 - accuracy: 0.9930 - val_loss: 0.4326 - val_accuracy: 0.8704\n",
            "Epoch 31/40\n",
            "30/30 [==============================] - 1s 38ms/step - loss: 0.0369 - accuracy: 0.9943 - val_loss: 0.4417 - val_accuracy: 0.8717\n",
            "Epoch 32/40\n",
            "30/30 [==============================] - 1s 25ms/step - loss: 0.0342 - accuracy: 0.9947 - val_loss: 0.4555 - val_accuracy: 0.8702\n",
            "Epoch 33/40\n",
            "30/30 [==============================] - 1s 24ms/step - loss: 0.0310 - accuracy: 0.9957 - val_loss: 0.4663 - val_accuracy: 0.8697\n",
            "Epoch 34/40\n",
            "30/30 [==============================] - 1s 25ms/step - loss: 0.0294 - accuracy: 0.9957 - val_loss: 0.4829 - val_accuracy: 0.8680\n",
            "Epoch 35/40\n",
            "30/30 [==============================] - 1s 29ms/step - loss: 0.0267 - accuracy: 0.9963 - val_loss: 0.4928 - val_accuracy: 0.8689\n",
            "Epoch 36/40\n",
            "30/30 [==============================] - 1s 24ms/step - loss: 0.0243 - accuracy: 0.9969 - val_loss: 0.5041 - val_accuracy: 0.8671\n",
            "Epoch 37/40\n",
            "30/30 [==============================] - 1s 24ms/step - loss: 0.0218 - accuracy: 0.9977 - val_loss: 0.5176 - val_accuracy: 0.8664\n",
            "Epoch 38/40\n",
            "30/30 [==============================] - 1s 30ms/step - loss: 0.0200 - accuracy: 0.9982 - val_loss: 0.5315 - val_accuracy: 0.8651\n",
            "Epoch 39/40\n",
            "30/30 [==============================] - 1s 24ms/step - loss: 0.0184 - accuracy: 0.9983 - val_loss: 0.5428 - val_accuracy: 0.8659\n",
            "Epoch 40/40\n",
            "30/30 [==============================] - 1s 31ms/step - loss: 0.0169 - accuracy: 0.9985 - val_loss: 0.5559 - val_accuracy: 0.8649\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4zIPJDcTPq3",
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6c4ecee-6ae7-40fd-a719-87251c3a9d63"
      },
      "source": [
        "results = model2.evaluate(X_test_enc, y_test)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 2s 3ms/step - loss: 0.5902 - accuracy: 0.8540\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "waS96edDTRyL",
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95dc31c1-5027-4b67-a9dd-205a6a3a517b"
      },
      "source": [
        "print (results)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.5902098417282104, 0.8539599776268005]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FBpTc_rXGvQ",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "The accuracy of model2 is ~87%. Using Embedding layer instead of one-hot layer improved the performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--020hfG6rN2",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# Model 3: Using pre-trained word embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GdY2-64YG1B",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Preparing pre-trained word embeddings (GLOVE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4gBeOyi4gkM",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "The Embedding layer can be used to load pre-trained word embeddings. We are going to use GloVe embeddings (https://nlp.stanford.edu/projects/glove/). GloVe stands for \"Global Vectors for Word Representation\". It's a popular embedding technique based on factorising a matrix of word co-occurence statistics. You can download GloVe and initialise the Keras Embedding layer with weights from the pre-trained embedding model for the words in your dataset.\n",
        "First, we need to read GloVe and map words to GloVe:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_PypdqG9Iis",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "def readGloveFile(gloveFile):\n",
        "    with open(gloveFile, 'r') as f:\n",
        "        wordToGlove = {}  \n",
        "        wordToIndex = {}  \n",
        "        indexToWord = {}  \n",
        "\n",
        "        for line in f:\n",
        "            record = line.strip().split()\n",
        "            token = record[0] \n",
        "            wordToGlove[token] = np.array(record[1:], dtype=np.float64) \n",
        "            \n",
        "        tokens = sorted(wordToGlove.keys())\n",
        "        for idx, tok in enumerate(tokens):\n",
        "            kerasIdx = idx + 1  \n",
        "            wordToIndex[tok] = kerasIdx \n",
        "            indexToWord[kerasIdx] = tok \n",
        "\n",
        "    return wordToIndex, indexToWord, wordToGlove"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcIZ3dq59bCh",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "Now, we create our pre-trained Embedding layer:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gembn7VM3ex8",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "from keras.initializers import Constant\n",
        "\n",
        "def createPretrainedEmbeddingLayer(wordToGlove, wordToIndex, isTrainable):\n",
        "    vocabLen = len(wordToIndex) + 1  \n",
        "    embDim = next(iter(wordToGlove.values())).shape[0]  \n",
        "   \n",
        "    embeddingMatrix = np.zeros((vocabLen, embDim))  \n",
        "    for word, index in wordToIndex.items():\n",
        "        embeddingMatrix[index, :] = wordToGlove[word] \n",
        "\n",
        "    embeddingLayer = Embedding(vocabLen, embDim, embeddings_initializer=Constant(embeddingMatrix), trainable=isTrainable, name='GloVe_Embeddings')\n",
        "    return embeddingLayer"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OC1wuctdFvA",
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc9bc5f1-3a98-4a49-cc9b-165ebf93c297"
      },
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip '/content/glove.6B.zip'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-09 13:52:36--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2023-03-09 13:52:37--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2023-03-09 13:52:37--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: â€˜glove.6B.zip.1â€™\n",
            "\n",
            "glove.6B.zip.1      100%[===================>] 822.24M  5.07MB/s    in 2m 39s  \n",
            "\n",
            "2023-03-09 13:55:17 (5.17 MB/s) - â€˜glove.6B.zip.1â€™ saved [862182613/862182613]\n",
            "\n",
            "Archive:  /content/glove.6B.zip\n",
            "replace glove.6B.50d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGxciLK4-xOr",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "We freeze the weights to create the layer: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZCPUM0W_Drc",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "# wordToIndex,indexToWord,wordToGlove=readGloveFile('/content/glove.6B.50d.txt')\n",
        "# wordToIndex,indexToWord,wordToGlove=readGloveFile('/content/glove.6B.100d.txt')\n",
        "wordToIndex,indexToWord,wordToGlove=readGloveFile('/content/glove.6B.300d.txt')\n",
        "\n",
        "# vocabLen = len(wordToIndex) + 1 \n",
        "\n",
        "EMBEDDING_SIZE = next(iter(wordToGlove.values())).shape[0]\n",
        "print('Size of Embedding: ',EMBED_SIZE)\n",
        "\n",
        "embeddingLayer=createPretrainedEmbeddingLayer(wordToGlove,wordToIndex,isTrainable=False)\n",
        "print(embeddingLayer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdZ4nl08vp9A",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Model 3-1: Neural Network model using pre-trained word embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VICS9rY8C7KH",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "input_layer = Input((MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
        "embed_layer = embeddingLayer(input_layer)\n",
        "averaging_layer = GlobalAveragePooling1DMasked()(embed_layer)\n",
        "hidden_layer = Dense(16)(averaging_layer)\n",
        "output = Dense(1, activation=\"sigmoid\")(hidden_layer)\n",
        "model3 = Model(inputs=[input_layer], outputs=[output])\n",
        "\n",
        "model3.summary()\n",
        "model3.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6sj_FnOD9Sb",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "history3 = model3.fit(partial_X_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=40,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(X_val, y_val),\n",
        "                    verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = model3.evaluate(X_test_enc, y_test)\n",
        "print(results)"
      ],
      "metadata": {
        "id": "tmB2z-9GcM1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxJhlT3whoDE",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "To compare freezing and fine-tuning the pre-trained embeding weights, we fine-tune the weights below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_xmeuuhhtbH",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "embeddingLayer=createPretrainedEmbeddingLayer(\n",
        "    wordToGlove, \n",
        "    wordToIndex, \n",
        "    isTrainable=True\n",
        "    )\n",
        "input_layer = Input((MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
        "embed_layer = embeddingLayer(input_layer)\n",
        "averaging_layer = GlobalAveragePooling1DMasked()(embed_layer)\n",
        "hidden_layer = Dense(16)(averaging_layer)\n",
        "output = Dense(1, activation=\"sigmoid\")(hidden_layer)\n",
        "model3 = Model(inputs=[input_layer], outputs=[output])\n",
        "\n",
        "model3.summary()\n",
        "model3.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rz8MEm6iHj6",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "# Train and test the model\n",
        "history3 = model3.fit(partial_X_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=40,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(X_val, y_val),\n",
        "                    verbose=1)\n",
        "results = model3.evaluate(X_test_enc, y_test)\n",
        "print(results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAdOh2IHnKuT",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "Experiments here show that fine-tuning the pre-trained embeddings would obtain better accuracy.\n",
        "\n",
        "**Note**: Use frozen pre-trained embeddings in the subsequent experiments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZ1KWFKvcagS",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "##  Model 3-2: LSTM with pre-trained word embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1lKisy3kb60",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "In lab 2, we have conducted an experiment with LSTMs. Now, we replace its embeddings with the pre-trained GLOVE embeddings."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import LSTM"
      ],
      "metadata": {
        "id": "4QIzG09qjCF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oz92rv2iTbo8",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "embeddingLayer=createPretrainedEmbeddingLayer(\n",
        "    wordToGlove, \n",
        "    wordToIndex, \n",
        "    isTrainable=False,\n",
        "    )\n",
        "input_layer = Input((MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
        "embed_layer = embeddingLayer(input_layer)\n",
        "lstm_step = LSTM(100, return_sequences=False)(embed_layer)\n",
        "output = Dense(1, activation=\"sigmoid\")(lstm_step)\n",
        "model3_2 = Model(inputs=[input_layer], outputs=[output])\n",
        "\n",
        "\n",
        "# label = Dense(1, activation='sigmoid')(final_lstm_step)\n",
        "\n",
        "model3_2.summary()\n",
        "model3_2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqyL_rhaUElx",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "# Train and test the model\n",
        "\n",
        "history3_2 = model3_2.fit(partial_X_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=40,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(X_val, y_val),\n",
        "                    verbose=1)\n",
        "results = model3_2.evaluate(X_test_enc, y_test)\n",
        "print(results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOqePi5-I1Xq",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "This experiment shows that simply replacing the lab 2 model embeddings with the pre-trained word embeddings (GLOVE) will cause performance to drop significantly. What can you do to improve the situation?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-bZ5SCHiIMl",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "#  Model 4: Adding extra dense layer into Neural Network model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G85QM3lSV7qp",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "We add extra dense layers into model 3-1 to evaluate their contribution. We start by adding one layer then two. All the other parameters are the same as for model 3-1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExgX8bxpVgps",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Adding one extra dense layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTgD_gMzXa1z",
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "7c0d2c60-15c8-48fa-ee24-965802ca132c"
      },
      "source": [
        "# your code goes here\n",
        "# Inspect model performance with 1 hidden layer, pre-trained embeddings\n",
        "embeddingLayer=createPretrainedEmbeddingLayer(\n",
        "    wordToGlove, \n",
        "    wordToIndex, \n",
        "    isTrainable=False,\n",
        "    )\n",
        "input_layer = Input((MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
        "embed_layer = embeddingLayer(input_layer)\n",
        "averaging_layer = GlobalAveragePooling1DMasked()(embed_layer)\n",
        "hidden_layer = Dense(16)(averaging_layer)\n",
        "output = Dense(1, activation=\"sigmoid\")(hidden_layer)\n",
        "model4 = Model(inputs=[input_layer], outputs=[output])\n",
        "\n",
        "model4.summary()\n",
        "# model4.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        " "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-e732106a56b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# your code goes here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Inspect model performance with 1 hidden layer, pre-trained embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m embeddingLayer=createPretrainedEmbeddingLayer(\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mwordToGlove\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mwordToIndex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'createPretrainedEmbeddingLayer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0npTvFuVt5R",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Adding two extra dense layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PowyhyRqcdDA",
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa850f08-4f9c-4231-f1e3-76e5d0c4a853"
      },
      "source": [
        "# your code goes here\n",
        "# Inspect model performance with 1 hidden layer, pre-trained embeddings\n",
        " "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Model_3_GloVe_Embeddings\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 256)]             0         \n",
            "                                                                 \n",
            " GloVe_Embeddings (Embedding  (None, 256, 300)         120000300 \n",
            " )                                                               \n",
            "                                                                 \n",
            " global_average_pooling1d_ma  (None, 300)              0         \n",
            " sked_5 (GlobalAveragePoolin                                     \n",
            " g1DMasked)                                                      \n",
            "                                                                 \n",
            " extra_dense_1 (Dense)       (None, 300)               90300     \n",
            "                                                                 \n",
            " extra_dense_2 (Dense)       (None, 100)               30100     \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 16)                1616      \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 120,122,333\n",
            "Trainable params: 122,033\n",
            "Non-trainable params: 120,000,300\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XisS32PaTATf",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "These two experiments show that adding extra dense layers can slightly improve accuracy over model 3-1.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrfC9Mu-RHID",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "#  Model 5: CNN for Text Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjOJrGCzwGM5",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "##  Model 5-1: Basic CNN model for Text Classification \n",
        "\n",
        "In this section, we build a Convolutional Neural Network (CNN) for text classification. We start by using one CNN layer and then adding another layer. You could use pre-trained embeddings or scratch train them from scratch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXBstOw0sCYF",
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22a53ad4-19b7-4a2a-e4ad-82a52206a75d"
      },
      "source": [
        "# your code goes here\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Model_4_CNN\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Input (InputLayer)          [(None, 256)]             0         \n",
            "                                                                 \n",
            " embedding_layer (Embedding)  (None, 256, 300)         3000000   \n",
            "                                                                 \n",
            " CNN1D (Conv1D)              (None, 251, 100)          180100    \n",
            "                                                                 \n",
            " MaxPool (GlobalMaxPooling1D  (None, 100)              0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " Output (Dense)              (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,180,201\n",
            "Trainable params: 3,180,201\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train and test the model, also plot train and validation accuracy and loss over epochs."
      ],
      "metadata": {
        "id": "jHZ96rkidrp-"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-G5MrDPJFBzK",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "# your code goes here\n",
        "\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkQMLxw-wWG6",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Model 5-2: Adding extra convolutional layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nvF662HOoqg",
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f00baed-3e0f-47c8-c77e-3ae4e3c235b4"
      },
      "source": [
        "# your code goes here\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Model_6_CNN\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Input (InputLayer)          [(None, 256)]             0         \n",
            "                                                                 \n",
            " embedding_layer (Embedding)  (None, 256, 300)         3000000   \n",
            "                                                                 \n",
            " CNN1D (Conv1D)              (None, 251, 100)          180100    \n",
            "                                                                 \n",
            " CNN1D2 (Conv1D)             (None, 246, 100)          60100     \n",
            "                                                                 \n",
            " MaxPool (GlobalMaxPooling1D  (None, 100)              0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " Output (Dense)              (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,240,301\n",
            "Trainable params: 3,240,301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train and test the model, also plot train and validation accuracy and loss over epochs."
      ],
      "metadata": {
        "id": "LIZREfaerXs2"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hx8JLl4xPlua",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "# your code goes here\n",
        "# Train and test the model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kx--Ytk3ZbLo",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "Although adding a layer here reduces the training loss, the evaluation accuracy is worse than for the model without the extra convolutional layer.\n",
        "\n",
        " Adding more layers can help you to extract more features. But we can do that up to a certain extent. After some point, instead of extracting features, we tend to overfit. Overfitting can lead to errors, such as false positives. It is not easy to choose the number of units in a hidden layer or the number of hidden layers in a neural network. For many applications, one hidden layer is enough. As a general rule, the number of units in this hidden layer is between the number of network input dimensions and the number of output dimensions.\n",
        " The best way to decide on the number of units and hidden layers is to try various parameters. Train several neural networks with different numbers of hidden layers and neurons, and monitor their performance.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gn2GSV4ioyO2",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    }
  ]
}