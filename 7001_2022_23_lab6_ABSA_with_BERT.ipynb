{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/josh-millar/josh-millar/blob/main/7001_2022_23_lab6_ABSA_with_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWgujXmGqzIC"
      },
      "source": [
        "# Lab 6 - Aspect-Based Sentiment Analysis with BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pr5PWYKGPi6R"
      },
      "source": [
        "In this lab we turn a pre-trained BERT model into a trainable Keras layer and apply it to the Aspect-Based Sentiment Analysis (ABSA). You can find the task description from (https://aclanthology.org/D19-1654.pdf).\n",
        "This task provides a review text dataset with aspects.\n",
        "Given a review and an aspect, we need to classify the sentiment conveyed towards this aspect on a three-point scale: POSITIVE, NEUTRAL or NEGATIVE.\n",
        "This is a multi-class classification task.\n",
        "\n",
        "BERT (Bidirectional Embedding Representations from Transformers) is a new model for pre-training language representations that obtains state-of-the-art results on many NLP tasks. We demonstrate how to integrate BERT as a custom Keras layer using the Huggingface library. \n",
        "\n",
        "In this lab, you will learn: \n",
        "\n",
        "1) How to use the Huggingface library.\n",
        "\n",
        "2) How to integrate BERT in the models built previously. \n",
        "\n",
        "3) How to use the TPU from Colab. **Note**: Running BERT on the CPU will be very slow. Thus we recommend you to do this lab on a Colab TPU provided by Google."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4spJ5PRhGJ1l"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "from keras.layers import Lambda, GlobalAveragePooling1D, Dense, Embedding\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.layers import LSTM, RNN, Dropout, Input, LeakyReLU, Bidirectional,Conv1D, GlobalMaxPooling1D\n",
        "from keras.layers.core import Dense\n",
        "from keras.models import Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oimYsLssuSs"
      },
      "source": [
        "We first need to install the Huggingface's Transformers package. You can find the relevant doc from [here](https://huggingface.co/transformers/index.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "AElpzsKFiZSo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97af1b6c-b911-4271-f416-3345b7aca9c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.6.2)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.13.1-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.2/199.2 KB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.14)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.13.1 tokenizers-0.13.2 transformers-4.26.1\n"
          ]
        }
      ],
      "source": [
        "pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebbamBD0xu5z"
      },
      "source": [
        "## Preprocessing and Tokenization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbAMXQwqyVT8"
      },
      "source": [
        "In this lab we will use DistilBERT (https://arxiv.org/pdf/1910.01108.pdf) instead of BERT: DistilBERT is a smaller and faster Transformer model trained via distilling BERT. It has 40% less parameters than the bert-base-uncased model. It runs 60% faster, while preserving 97% of BERT’s performance as measured on the GLUE language understanding benchmark.\n",
        "\n",
        "It is easy to switch between DistilBERT and BERT using the Huggingface transformers package. This package provides many pre-trained and pre-built models that are easy to use via a few lines of code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-cUTxt02dQb"
      },
      "source": [
        "Before using DistilBERT or BERT, we need a tokenizer. Generally speaking, every BERT related model has its own tokenizer, trained for this particular model. \n",
        "We can get the DistilBERT tokenizer from the **DistilBertTokenizer.from_pretrained** method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "hKj6Y_TydjeS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "c4a981cc30014b77b7670346539ee0ea",
            "2b34a4df965c46c09ed3ed63cb29eb43",
            "e77e076a14df419baeb0c9e0155c4a6b",
            "3fb4ecd439dd4e4c9fed9b52f0376d53",
            "ff7a7a473af74d1d8af73a1ef839f662",
            "8318f933cbf34c128cbb411a27bc9d11",
            "2e99f1b72bdf45cfb1b689b1484a3405",
            "67779d7c0a1e45cab91a4dc25dc1e553",
            "cf17db91a185485e804d7fbfd5b6d9ff",
            "fe3f5a9927d64c96b79c0e0a52142e19",
            "ba04c0fdcfbe4f69ac33bcd5984facdb",
            "ee989fd1ad4c4901bfc7f2cf51b3a79a",
            "b21aab5dc9d0413a9a6b04969c1a8111",
            "3727581133c345c597faaaa539d7256f",
            "c3c6e0f6d9c34ae882d9276dfd491809",
            "949d9af37dd34b7e8b9aecc1490bc24e",
            "bfb8dc21c419405383c951159aeb5e7d",
            "0d25d62b438e4583bdd27a6c0d1f3c28",
            "9e8834093d0045d5af649e4a6a89be4a",
            "280860a835d8443e9159c344caf437f0",
            "0a21067d914d41cfa8c375d826b17a3e",
            "ee72902f437c487ab43cde98d224b421",
            "a70f83babaa04f65b676345be9f4789b",
            "6756452aa3a14edeaa6ada158d23ac27",
            "524d73066ffe4dbaacd46f123dadb63b",
            "95af3c619ac54ca2986d94611a7c5b36",
            "ea3fed974beb4ea4bd59327a65f4d7ab",
            "1c85a8f600db46f3b27b90f99f16eada",
            "956ca8a19d20415c8880107dbd3732e1",
            "b1d7ecc1a35f4b80b98c4dba3c34091e",
            "ad7a2de770ef440e93f1577e7a6a5cdf",
            "724596496b144538aed56a8fea24593e",
            "fcda7f10fe8e4b73991e8eb70c52d009"
          ]
        },
        "outputId": "87054645-a08d-4195-aaf1-276e7134d55c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c4a981cc30014b77b7670346539ee0ea"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ee989fd1ad4c4901bfc7f2cf51b3a79a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a70f83babaa04f65b676345be9f4789b"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from transformers import DistilBertTokenizer, RobertaTokenizer \n",
        "import tqdm\n",
        "distil_bert = 'distilbert-base-uncased' # Pick a pre-trained model\n",
        "\n",
        "# Defining DistilBERT tokenizer\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(distil_bert, do_lower_case=True, add_special_tokens=True,\n",
        "                                                max_length=128, pad_to_max_length=True)\n",
        "\n",
        "def tokenize(sentences, tokenizer, pad_length=128, pad_to_max_length=True ):\n",
        "    if type(sentences) == str:\n",
        "        inputs = tokenizer.encode_plus(sentences, add_special_tokens=True, max_length=pad_length, pad_to_max_length=pad_to_max_length, \n",
        "                                             return_attention_mask=True, return_token_type_ids=True)\n",
        "        return np.asarray(inputs['input_ids'], dtype='int32'), np.asarray(inputs['attention_mask'], dtype='int32'), np.asarray(inputs['token_type_ids'], dtype='int32')\n",
        "    \n",
        "    input_ids, input_masks, input_segments = [],[],[]\n",
        "    for sentence in sentences:\n",
        "        inputs = tokenizer.encode_plus(sentence, add_special_tokens=True, max_length=pad_length, pad_to_max_length=pad_to_max_length, \n",
        "                                             return_attention_mask=True, return_token_type_ids=True)\n",
        "        input_ids.append(inputs['input_ids'])\n",
        "        input_masks.append(inputs['attention_mask'])\n",
        "        input_segments.append(inputs['token_type_ids'])        \n",
        "        \n",
        "    return np.asarray(input_ids, dtype='int32'), np.asarray(input_masks, dtype='int32'), np.asarray(input_segments, dtype='int32')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqMo6CPS3qJZ"
      },
      "source": [
        "Then we can use this tokenizer to tokenize our data. When working with word2vec and GloVe, we tokenized sentences into words ourselves and then converted the tokens into GloVe indices. But in BERT, we must use the BERT tokenizer that uses sub-word tokens.\n",
        "\n",
        "For example, for the sentence: **This is a pretrained model.** our previous word-based tokenizer will generate the following tokens:\n",
        "\n",
        "**\"this\", \"is\", \"a\", \"pretrained\", \"model\", \".\"**\n",
        "\n",
        "Then you will find out that the token \"pretrained\" is not in the GloVe word dictionary. Thus we can not assign it a trained word vector.\n",
        "\n",
        "The BERT tokenizer will separate the word \"pretrained\" into three sub-word tokens:\n",
        "\n",
        "**'pre', '##train', '##ed'**\n",
        "\n",
        "BERT thus uses these three token vectors to represent the word \"pretrained\". You will also see that the BERT tokenizer adds the special [CLS] token and the sentence separator [SEP] token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "iRoKe2DKyi41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a96d7785-3f8d-4227-e060-a92324b57eb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['the', 'capital', 'of', 'france', 'is', '[MASK]', '.'] \n",
            "\n",
            "['this', 'is', 'a', 'pre', '##train', '##ed', 'model', '.'] \n",
            "\n",
            "[ 101 1996 3007 1997 2605 2003  103 1012  102    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0]\n",
            "[1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "['[CLS]', 'the', 'capital', 'of', 'france', 'is', '[MASK]', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]'] \n",
            "\n",
            "[ 101 1996 3007 1997 2605 2003  103 1012  102]\n",
            "[1 1 1 1 1 1 1 1 1]\n",
            "['[CLS]', 'the', 'capital', 'of', 'france', 'is', '[MASK]', '.', '[SEP]'] \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2339: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "inputs = tokenizer.tokenize(\"The capital of France is [MASK].\")\n",
        "print(inputs,'\\n')\n",
        "\n",
        "inputs = tokenizer.tokenize(\"This is a pretrained model.\")\n",
        "print(inputs,'\\n')\n",
        "\n",
        "ids,masks,segments = tokenize(\"The capital of France is [MASK].\", tokenizer)\n",
        "print(ids)\n",
        "print(masks)\n",
        "print(tokenizer.convert_ids_to_tokens(ids),\"\\n\")\n",
        "\n",
        "ids,masks,segments = tokenize(\"The capital of France is [MASK].\", tokenizer, pad_to_max_length=False)\n",
        "print(ids)\n",
        "print(masks)\n",
        "print(tokenizer.convert_ids_to_tokens(ids),\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6OuZAA8sbdg"
      },
      "source": [
        "## Loading Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqvPQvgvPv1W"
      },
      "source": [
        "### Downloading and preprocessing data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EundMtGPpCdf"
      },
      "source": [
        "Unlike the IMDB dataset that is included and preprocessed by Keras, the dataset we will be using is the aspect-based sentiment analysis (ABSA)  dataset, which consists of 5,297 labeled reviews. These are split into 4,297 reviews for training and 500 reviews for testing and validation, respectively. \n",
        "\n",
        "For ABSA, sentiment polarities were assigned with respect to the aspect terms.  The start and end positions for each aspect term are provided.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "NyuSzkafqNca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec1f7243-860b-4d3d-9e87-8dc19da814ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training entries: 11186\n",
            "Test entries: 1336\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "def downloadfile(url):\n",
        "  rq = requests.get(url)\n",
        "  open(url.split('/')[-1], 'wb').write(rq.content)\n",
        "downloadfile('https://raw.githubusercontent.com/siat-nlp/MAMS-for-ABSA/master/data/MAMS-ATSA/raw/train.xml')\n",
        "downloadfile('https://raw.githubusercontent.com/siat-nlp/MAMS-for-ABSA/master/data/MAMS-ATSA/raw/val.xml')\n",
        "downloadfile('https://raw.githubusercontent.com/siat-nlp/MAMS-for-ABSA/master/data/MAMS-ATSA/raw/test.xml')\n",
        "\n",
        "\n",
        "# The code is modified from https://raw.githubusercontent.com/siat-nlp/MAMS-for-ABSA/master/data_process/utils.py\n",
        "from xml.etree.ElementTree import parse\n",
        "\n",
        "def parse_sentence_term(path, lowercase=False):\n",
        "    tree = parse(path)\n",
        "    sentences = tree.getroot()\n",
        "    data = []\n",
        "    split_char = '__split__'\n",
        "    for sentence in sentences:\n",
        "        text = sentence.find('text')\n",
        "        if text is None:\n",
        "            continue\n",
        "        text = text.text\n",
        "        if lowercase:\n",
        "            text = text.lower()\n",
        "        aspectTerms = sentence.find('aspectTerms')\n",
        "        if aspectTerms is None:\n",
        "            continue\n",
        "        for aspectTerm in aspectTerms:\n",
        "            term = aspectTerm.get('term')\n",
        "            if lowercase:\n",
        "                term = term.lower()\n",
        "            polarity = aspectTerm.get('polarity')\n",
        "            start = aspectTerm.get('from')\n",
        "            end = aspectTerm.get('to')\n",
        "            piece = [text , term,  polarity , start , end]\n",
        "            data.append(piece)\n",
        "    return data\n",
        "train = parse_sentence_term(\"train.xml\",True)\n",
        "dev = parse_sentence_term(\"val.xml\",True)\n",
        "test = parse_sentence_term(\"test.xml\",True)\n",
        "\n",
        "print(\"Training entries: {}\".format(len(train)))\n",
        "print(\"Test entries: {}\".format(len(test)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6U4iCV9-rmay"
      },
      "source": [
        "Let’s first see some examples from the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "h-gjWRAuqg5s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d76727e4-019b-4862-c104-de8d12be8871"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SENTENCE \t ASPECT \t LABEL \t ASPECT-START-INDEX \t ASPECT-END-INDEX\n",
            "['decor', 'food', 'prices', 'tables', 'manager']\n"
          ]
        }
      ],
      "source": [
        "print(\"SENTENCE \\t ASPECT \\t LABEL \\t ASPECT-START-INDEX \\t ASPECT-END-INDEX\")\n",
        "print([a[1] for a in train[0:5]])\n",
        "# print(train[1])\n",
        "# print(train[2])\n",
        "# print(train[3])\n",
        "# print(train[4])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tvuu4KhStqei"
      },
      "source": [
        "Using the BERT `tokenize` function above, we can text and aspect words to integers:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "gMCH1OoDrSNR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e94bfc64-7fdc-4462-914f-b314e4605954"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_dev_aspect_int[0]:\n",
            "[ 101 8974  102    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0]\n",
            "x_dev_aspect_masks[0]:\n",
            "[1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "x_dev_review_int[0]:\n",
            "[  101  2044  1037  3232  1997  8974  1010  1996 18726  1011  1011  1045\n",
            "  2066  1996 27940  1013 24792  2621  4897  1998  1996 13675 11514  6508\n",
            " 26852  1011  1011  2175  2091  2307  1012   102     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0]\n",
            "x_dev_review_masks[0]:\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ],
      "source": [
        "# Please write your code to generate the following data\n",
        "x_train_review_int, x_train_review_masks, _ = tokenize([r[0] for r in train], tokenizer)\n",
        "x_train_aspect_int, x_train_aspect_masks, _ = tokenize([r[1] for r in train], tokenizer)\n",
        "\n",
        "x_dev_review_int, x_dev_review_masks, _ = tokenize([r[0] for r in dev], tokenizer)\n",
        "x_dev_aspect_int, x_dev_aspect_masks, _ = tokenize([r[1] for r in dev], tokenizer)\n",
        "\n",
        "x_test_review_int, x_test_review_masks, _ = tokenize([r[0] for r in test], tokenizer)\n",
        "x_test_aspect_int, x_test_aspect_masks, _ = tokenize([r[1] for r in test], tokenizer)\n",
        "# x_train_review_int\n",
        "# x_train_review_masks\n",
        "# x_train_aspect_int\n",
        "# x_train_aspect_masks\n",
        "\n",
        "# x_dev_review_int\n",
        "# x_dev_review_masks\n",
        "# x_dev_aspect_int\n",
        "# x_dev_aspect_masks\n",
        "\n",
        "# x_test_review_int\n",
        "# x_test_review_masks\n",
        "# x_test_aspect_int\n",
        "# x_test_aspect_masks\n",
        "\n",
        "# your code goes here\n",
        "\n",
        "# You can check the results as follows:\n",
        "assert len(x_train_aspect_int) == len(train)\n",
        "assert len(x_train_aspect_masks) == len(x_train_aspect_int)\n",
        "assert len(x_test_aspect_int) == len(test)\n",
        "assert len(x_test_aspect_masks) == len(x_test_aspect_int)\n",
        "print(\"x_dev_aspect_int[0]:\")\n",
        "print(x_dev_aspect_int[0])\n",
        "print(\"x_dev_aspect_masks[0]:\")\n",
        "print(x_dev_aspect_masks[0])\n",
        "print(\"x_dev_review_int[0]:\")\n",
        "print(x_dev_review_int[0])\n",
        "print(\"x_dev_review_masks[0]:\")\n",
        "print(x_dev_review_masks[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IreFXgruZot"
      },
      "source": [
        "We one-hot encode the labels, using 4 (Binary:100) to represent \"positive\", 2 (Binary:010) for \"neutral\", and 1 (Binary:001) for \"negative\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "abIb7Fe5u3GQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9294f1e-86b9-4516-8158-f2666c8c8b5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 1]\n",
            "[1 0 0]\n",
            "[1 0 0]\n",
            "[0 1 0]\n",
            "[0 0 1]\n"
          ]
        }
      ],
      "source": [
        "def label2int(dataset):\n",
        "  y = []\n",
        "  for example in dataset:\n",
        "    if example[2].lower() == \"negative\":\n",
        "      y.append([0,0,1])\n",
        "    elif example[2].lower() == \"neutral\":\n",
        "      y.append([0,1,0])\n",
        "    else:\n",
        "      # assert example[2].lower() == \"positive\"\n",
        "      y.append([1,0,0])\n",
        "  return y\n",
        "  \n",
        "y_train = label2int(train)\n",
        "y_dev = label2int(dev)\n",
        "y_test = label2int(test)\n",
        "y_train = np.array(y_train)\n",
        "y_dev = np.array(y_dev)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "print(y_train[0])\n",
        "print(y_train[1])\n",
        "print(y_train[2])\n",
        "print(y_train[3])\n",
        "print(y_train[4])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9TnnSuspvC5b"
      },
      "source": [
        "Now we have almost finished the data preprocessing. Unlike in the previous labs, there are two model inputs: review and aspect. The easiest way is to combine the review and aspect into one sentence and then input it into the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "nKOiVVXQu-_I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1a752a9-0b8e-4e62-b228-5928905d1def"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  101  2044  1037  3232  1997  8974  1010  1996 18726  1011  1011  1045\n",
            "  2066  1996 27940  1013 24792  2621  4897  1998  1996 13675 11514  6508\n",
            " 26852  1011  1011  2175  2091  2307  1012   102  8974   102     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] \n",
            "\n",
            "[  101  2044  1037  3232  1997  8974  1010  1996 18726  1011  1011  1045\n",
            "  2066  1996 27940  1013 24792  2621  4897  1998  1996 13675 11514  6508\n",
            " 26852  1011  1011  2175  2091  2307  1012   102  8974   102     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ],
      "source": [
        "# Please write your code to combine sentences and aspect words into the following varibles\n",
        "\n",
        "# x_train_int\n",
        "# x_train_masks\n",
        "# x_dev_int\n",
        "# x_dev_masks\n",
        "# x_test_int\n",
        "# x_test_masks\n",
        "\n",
        "# Tips: \n",
        "# 1) Use the special token <SEP> to concatenate sentences and aspect words\n",
        "# 2) Make sure they are paded/truncated to a max length\n",
        "\n",
        "# your code goes here\n",
        "\n",
        "x_train_sentences = [r[0] for r in train]\n",
        "x_train_aspects = [r[1] for r in train]\n",
        "x_train_joined = []\n",
        "for idx, sentence in enumerate(x_train_sentences):\n",
        "    x_train_joined.append(' [SEP] '.join([sentence, x_train_aspects[idx]]))\n",
        "x_train_int, x_train_masks, _ = tokenize(x_train_joined, tokenizer)\n",
        "\n",
        "x_dev_sentences = [r[0] for r in dev]\n",
        "x_dev_aspects = [r[1] for r in dev]\n",
        "x_dev_joined = []\n",
        "for idx, sentence in enumerate(x_dev_sentences):\n",
        "    x_dev_joined.append(' [SEP] '.join([sentence, x_dev_aspects[idx]]))\n",
        "x_dev_int, x_dev_masks, _ = tokenize(x_dev_joined, tokenizer)\n",
        "\n",
        "x_test_sentences = [r[0] for r in test]\n",
        "x_test_aspects = [r[1] for r in test]\n",
        "x_test_joined = []\n",
        "for idx, sentence in enumerate(x_test_sentences):\n",
        "    x_test_joined.append(' [SEP] '.join([sentence, x_test_aspects[idx]]))\n",
        "x_test_int, x_test_masks, _ = tokenize(x_test_joined, tokenizer)\n",
        "\n",
        "# Don't forget the to use the np.array function to wrap the outputs\n",
        "x_train_int_np = np.array(x_train_int)\n",
        "x_train_masks_np = np.array(x_train_masks)\n",
        "x_dev_int_np = np.array(x_dev_int)\n",
        "x_dev_masks_np = np.array(x_dev_masks)\n",
        "x_test_int_np = np.array(x_test_int)\n",
        "x_test_masks_np = np.array(x_test_masks)\n",
        "\n",
        "\n",
        "print(x_dev_int[0])\n",
        "print(x_dev_masks[0],'\\n')\n",
        "print(x_dev_int_np[0])\n",
        "print(x_dev_masks_np[0]) # sentence + aspect\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqvUGIwwGJqu"
      },
      "source": [
        "## Model 1: Prebuilt Sequence Classification\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSxC41ln07im"
      },
      "source": [
        "The Huggingface transformer package provides many prebuilt models. Now let us try a sequence classification model based on DistilBERT. \n",
        "\n",
        "The models with BERT are much bigger than our previous models. To run it faster, we can use TPU. Detailed guidelines on how to use TPU can be found from https://www.tensorflow.org/guide/tpu."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "1gXFbb2cxBlw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45b7ee84-8809-4c45-befe-47b00443614d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.96.80.66:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n",
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForSequenceClassification: ['vocab_transform', 'vocab_projector', 'activation_13', 'vocab_layer_norm']\n",
            "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier', 'pre_classifier', 'dropout_96']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TFSequenceClassifierOutput(loss=None, logits=<KerasTensor: shape=(None, 3) dtype=float32 (created by layer 'tf_distil_bert_for_sequence_classification_1')>, hidden_states=None, attentions=None)\n"
          ]
        }
      ],
      "source": [
        "from transformers import TFDistilBertForSequenceClassification, DistilBertConfig\n",
        "import tensorflow as tf\n",
        "\n",
        "distil_bert = 'distilbert-base-uncased'\n",
        "\n",
        "config = DistilBertConfig(num_labels=3)\n",
        "config.output_hidden_states = False\n",
        "\n",
        "def create_TFDistilBertForSequenceClassification():\n",
        "  transformer_model = TFDistilBertForSequenceClassification.from_pretrained(distil_bert, config = config)\n",
        "  input_ids = tf.keras.layers.Input(shape=(128,), name='input_token', dtype='int32')\n",
        "  input_masks_ids = tf.keras.layers.Input(shape=(128,), name='masked_token', dtype='int32')\n",
        "  X = transformer_model(input_ids, input_masks_ids)\n",
        "  print(X)\n",
        "  return tf.keras.Model(inputs=[input_ids, input_masks_ids], outputs = X)\n",
        "\n",
        "use_tpu = True\n",
        "if use_tpu:\n",
        "  # Create distribution strategy\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "  tf.config.experimental_connect_to_cluster(tpu)\n",
        "  tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "  strategy = tf.distribute.TPUStrategy(tpu)\n",
        "\n",
        "  # Create model on TPU:\n",
        "  with strategy.scope():\n",
        "    model = create_TFDistilBertForSequenceClassification()\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
        "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "else:\n",
        "  model = create_TFDistilBertForSequenceClassification()\n",
        "  model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "2CPFj0CMx9mw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "347d89ee-f3a2-4514-a845-d832b074ffb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_token (InputLayer)       [(None, 128)]        0           []                               \n",
            "                                                                                                  \n",
            " masked_token (InputLayer)      [(None, 128)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_distil_bert_for_sequence_cl  TFSequenceClassifie  66955779   ['input_token[0][0]',            \n",
            " assification (TFDistilBertForS  rOutput(loss=None,               'masked_token[0][0]']           \n",
            " equenceClassification)         logits=(None, 3),                                                 \n",
            "                                 hidden_states=None                                               \n",
            "                                , attentions=None)                                                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 66,955,779\n",
            "Trainable params: 66,955,779\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "zQQH5lE_33Vn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8750bdd6-51aa-4ccf-9498-a21effb24761"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "22/22 [==============================] - 103s 2s/step - loss: 0.8053 - accuracy: 0.4279 - val_loss: 0.5899 - val_accuracy: 0.4677\n",
            "Epoch 2/30\n",
            "22/22 [==============================] - 5s 224ms/step - loss: 0.5787 - accuracy: 0.4891 - val_loss: 0.5743 - val_accuracy: 0.5150\n",
            "Epoch 3/30\n",
            "22/22 [==============================] - 5s 230ms/step - loss: 0.5210 - accuracy: 0.6156 - val_loss: 0.4638 - val_accuracy: 0.7072\n",
            "Epoch 4/30\n",
            "22/22 [==============================] - 5s 224ms/step - loss: 0.4305 - accuracy: 0.7354 - val_loss: 0.4378 - val_accuracy: 0.7417\n",
            "Epoch 5/30\n",
            "22/22 [==============================] - 5s 223ms/step - loss: 0.4178 - accuracy: 0.7424 - val_loss: 0.4846 - val_accuracy: 0.7635\n",
            "Epoch 6/30\n",
            "22/22 [==============================] - 5s 230ms/step - loss: 0.3581 - accuracy: 0.8019 - val_loss: 0.4752 - val_accuracy: 0.7740\n",
            "Epoch 7/30\n",
            "22/22 [==============================] - 5s 223ms/step - loss: 0.3414 - accuracy: 0.8158 - val_loss: 0.4747 - val_accuracy: 0.7875\n",
            "Epoch 8/30\n",
            "22/22 [==============================] - 5s 222ms/step - loss: 0.3010 - accuracy: 0.8358 - val_loss: 0.4553 - val_accuracy: 0.8056\n",
            "Epoch 9/30\n",
            "22/22 [==============================] - 5s 231ms/step - loss: 0.3010 - accuracy: 0.8444 - val_loss: 0.3817 - val_accuracy: 0.7950\n",
            "Epoch 10/30\n",
            "22/22 [==============================] - 5s 224ms/step - loss: 0.2606 - accuracy: 0.8744 - val_loss: 0.5455 - val_accuracy: 0.8056\n",
            "Epoch 11/30\n",
            "22/22 [==============================] - 5s 222ms/step - loss: 0.3111 - accuracy: 0.8175 - val_loss: 0.5004 - val_accuracy: 0.7673\n",
            "Epoch 12/30\n",
            "22/22 [==============================] - 5s 233ms/step - loss: 0.2498 - accuracy: 0.8754 - val_loss: 0.5268 - val_accuracy: 0.7988\n",
            "Epoch 13/30\n",
            "22/22 [==============================] - 5s 224ms/step - loss: 0.2281 - accuracy: 0.8920 - val_loss: 0.6606 - val_accuracy: 0.7763\n",
            "Epoch 14/30\n",
            "22/22 [==============================] - 5s 223ms/step - loss: 0.3436 - accuracy: 0.8380 - val_loss: 0.5777 - val_accuracy: 0.7928\n",
            "Epoch 15/30\n",
            "22/22 [==============================] - 5s 224ms/step - loss: 0.2424 - accuracy: 0.8901 - val_loss: 0.6693 - val_accuracy: 0.7883\n",
            "Epoch 16/30\n",
            "22/22 [==============================] - 5s 225ms/step - loss: 0.1925 - accuracy: 0.9079 - val_loss: 0.6109 - val_accuracy: 0.7988\n",
            "Epoch 17/30\n",
            "22/22 [==============================] - 5s 229ms/step - loss: 0.1837 - accuracy: 0.9136 - val_loss: 0.6858 - val_accuracy: 0.8018\n",
            "Epoch 18/30\n",
            "22/22 [==============================] - 5s 224ms/step - loss: 0.1679 - accuracy: 0.9209 - val_loss: 0.6633 - val_accuracy: 0.7943\n",
            "Epoch 19/30\n",
            "22/22 [==============================] - 5s 224ms/step - loss: 0.1558 - accuracy: 0.9298 - val_loss: 0.8785 - val_accuracy: 0.7950\n",
            "Epoch 20/30\n",
            "22/22 [==============================] - 5s 231ms/step - loss: 0.1318 - accuracy: 0.9423 - val_loss: 0.8826 - val_accuracy: 0.7875\n",
            "Epoch 21/30\n",
            "22/22 [==============================] - 5s 224ms/step - loss: 0.1432 - accuracy: 0.9379 - val_loss: 0.7593 - val_accuracy: 0.7905\n",
            "Epoch 22/30\n",
            "22/22 [==============================] - 5s 223ms/step - loss: 0.1291 - accuracy: 0.9431 - val_loss: 0.9936 - val_accuracy: 0.7785\n",
            "Epoch 23/30\n",
            "22/22 [==============================] - 5s 230ms/step - loss: 0.1322 - accuracy: 0.9450 - val_loss: 0.9327 - val_accuracy: 0.7785\n",
            "Epoch 24/30\n",
            "22/22 [==============================] - 5s 222ms/step - loss: 0.1320 - accuracy: 0.9439 - val_loss: 0.8530 - val_accuracy: 0.7913\n",
            "Epoch 25/30\n",
            "22/22 [==============================] - 5s 224ms/step - loss: 0.0905 - accuracy: 0.9631 - val_loss: 1.0244 - val_accuracy: 0.8011\n",
            "Epoch 26/30\n",
            "22/22 [==============================] - 6s 266ms/step - loss: 0.0755 - accuracy: 0.9679 - val_loss: 1.1647 - val_accuracy: 0.7905\n",
            "Epoch 27/30\n",
            "22/22 [==============================] - 5s 224ms/step - loss: 0.0619 - accuracy: 0.9757 - val_loss: 1.2864 - val_accuracy: 0.8003\n",
            "Epoch 28/30\n",
            "22/22 [==============================] - 5s 225ms/step - loss: 0.1385 - accuracy: 0.9516 - val_loss: 1.1254 - val_accuracy: 0.7838\n",
            "Epoch 29/30\n",
            "22/22 [==============================] - 5s 226ms/step - loss: 0.1966 - accuracy: 0.9347 - val_loss: 0.8829 - val_accuracy: 0.7883\n",
            "Epoch 30/30\n",
            "22/22 [==============================] - 5s 224ms/step - loss: 0.1351 - accuracy: 0.9465 - val_loss: 0.8350 - val_accuracy: 0.7950\n"
          ]
        }
      ],
      "source": [
        "history = model.fit([x_train_int_np,x_train_masks_np],\n",
        "                    y_train,\n",
        "                    epochs=30,\n",
        "                    batch_size=512,\n",
        "                    validation_data=([x_dev_int_np,x_dev_masks_np], y_dev),\n",
        "                    verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "lQcytuBdaWVp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "330c9d32-8d6f-4df8-d37e-52331fac1f6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42/42 [==============================] - 8s 100ms/step - loss: 0.7821 - accuracy: 0.7964\n",
            "[0.7820532321929932, 0.796407163143158]\n"
          ]
        }
      ],
      "source": [
        "results = model.evaluate([x_test_int_np,x_test_masks_np], y_test)\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdZ4nl08vp9A"
      },
      "source": [
        "\n",
        "## Model 2: Neural bag of words using BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gyCwXFj_R5w"
      },
      "source": [
        "Here we will use model2 from Lab3 with BERT instead of the previous static word embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "DStlnRQRf-4v"
      },
      "outputs": [],
      "source": [
        "class GlobalAveragePooling1DMasked(GlobalAveragePooling1D):\n",
        "    def call(self, x, mask=None):\n",
        "        if mask != None:\n",
        "            return K.sum(x, axis=1) / K.sum(mask, axis=1)\n",
        "        else:\n",
        "            return super().call(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "8fTwmYDvNEyT"
      },
      "outputs": [],
      "source": [
        "from transformers import TFDistilBertModel, DistilBertConfig\n",
        "\n",
        "def get_BERT_layer():\n",
        "  distil_bert = 'distilbert-base-uncased'\n",
        "  config = DistilBertConfig(dropout=0.2, attention_dropout=0.2)\n",
        "  config.output_hidden_states = False\n",
        "  return TFDistilBertModel.from_pretrained(distil_bert, config = config)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "VICS9rY8C7KH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c266e1c5-9dc3-49ae-841c-48782bfa8e79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.96.80.66:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n",
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_transform', 'vocab_projector', 'activation_13', 'vocab_layer_norm']\n",
            "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "hdepth=16\n",
        "MAX_SEQUENCE_LENGTH = 128\n",
        "EMBED_SIZE=100\n",
        "\n",
        "\n",
        "def create_bag_of_words_BERT():\n",
        "  # your code goes here\n",
        "  input_ids_in = tf.keras.layers.Input(shape=(128,), name='input_token', dtype='int32')\n",
        "  input_masks_in = tf.keras.layers.Input(shape=(128,), name='masked_token', dtype='int32')\n",
        "  bert_model = get_BERT_layer()\n",
        "  bert_layer = bert_model(input_ids_in, input_masks_in)\n",
        "  averaging_layer = GlobalAveragePooling1DMasked()(bert_layer.last_hidden_state)\n",
        "  hidden_layer = Dense(16)(averaging_layer)\n",
        "  label = Dense(3, activation='sigmoid')(hidden_layer)\n",
        "  return Model(inputs=[input_ids_in,input_masks_in], outputs=[label],name='Model2_BERT')\n",
        "\n",
        "use_tpu = True\n",
        "if use_tpu:\n",
        "  # Create distribution strategy\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "  tf.config.experimental_connect_to_cluster(tpu)\n",
        "  tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "  strategy = tf.distribute.TPUStrategy(tpu)\n",
        "\n",
        "  # Create model\n",
        "  with strategy.scope():\n",
        "    model2 = create_bag_of_words_BERT()\n",
        "    optimizer2 = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
        "    model2.compile(optimizer=optimizer2, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "else:\n",
        "  model2 = create_bag_of_words_BERT()\n",
        "  model2.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2.summary() "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GebkoriE5daJ",
        "outputId": "c2d29965-0ed1-4879-dbcf-bd08e637c233"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Model2_BERT\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_token (InputLayer)       [(None, 128)]        0           []                               \n",
            "                                                                                                  \n",
            " masked_token (InputLayer)      [(None, 128)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_distil_bert_model_6 (TFDist  TFBaseModelOutput(l  66362880   ['input_token[0][0]',            \n",
            " ilBertModel)                   ast_hidden_state=(N               'masked_token[0][0]']           \n",
            "                                one, 128, 768),                                                   \n",
            "                                 hidden_states=None                                               \n",
            "                                , attentions=None)                                                \n",
            "                                                                                                  \n",
            " global_average_pooling1d_maske  (None, 768)         0           ['tf_distil_bert_model_6[0][0]'] \n",
            " d_6 (GlobalAveragePooling1DMas                                                                   \n",
            " ked)                                                                                             \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 16)           12304       ['global_average_pooling1d_masked\n",
            "                                                                 _6[0][0]']                       \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 3)            51          ['dense_4[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 66,375,235\n",
            "Trainable params: 66,375,235\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "S0SbsCsxF1zi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5425207a-a86c-4ea7-f770-fb6fe8cabf21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "22/22 [==============================] - 105s 2s/step - loss: 0.6135 - accuracy: 0.4601 - val_loss: 0.5551 - val_accuracy: 0.5270\n",
            "Epoch 2/30\n",
            "22/22 [==============================] - 5s 232ms/step - loss: 0.4988 - accuracy: 0.6068 - val_loss: 0.4192 - val_accuracy: 0.7237\n",
            "Epoch 3/30\n",
            "22/22 [==============================] - 5s 222ms/step - loss: 0.3607 - accuracy: 0.7520 - val_loss: 0.3312 - val_accuracy: 0.7890\n",
            "Epoch 4/30\n",
            "22/22 [==============================] - 5s 226ms/step - loss: 0.2876 - accuracy: 0.8152 - val_loss: 0.3068 - val_accuracy: 0.8078\n",
            "Epoch 5/30\n",
            "22/22 [==============================] - 5s 232ms/step - loss: 0.2327 - accuracy: 0.8567 - val_loss: 0.3124 - val_accuracy: 0.8153\n",
            "Epoch 6/30\n",
            "22/22 [==============================] - 5s 222ms/step - loss: 0.1881 - accuracy: 0.8918 - val_loss: 0.3344 - val_accuracy: 0.8251\n",
            "Epoch 7/30\n",
            "22/22 [==============================] - 5s 224ms/step - loss: 0.1522 - accuracy: 0.9093 - val_loss: 0.3568 - val_accuracy: 0.8153\n",
            "Epoch 8/30\n",
            "22/22 [==============================] - 5s 227ms/step - loss: 0.1298 - accuracy: 0.9251 - val_loss: 0.3860 - val_accuracy: 0.8131\n",
            "Epoch 9/30\n",
            "22/22 [==============================] - 5s 223ms/step - loss: 0.1108 - accuracy: 0.9360 - val_loss: 0.3873 - val_accuracy: 0.8221\n",
            "Epoch 10/30\n",
            "22/22 [==============================] - 7s 339ms/step - loss: 0.0830 - accuracy: 0.9564 - val_loss: 0.4625 - val_accuracy: 0.8146\n",
            "Epoch 11/30\n",
            "22/22 [==============================] - 5s 235ms/step - loss: 0.0641 - accuracy: 0.9645 - val_loss: 0.4789 - val_accuracy: 0.8146\n",
            "Epoch 12/30\n",
            "22/22 [==============================] - 5s 224ms/step - loss: 0.0515 - accuracy: 0.9726 - val_loss: 0.4856 - val_accuracy: 0.8176\n",
            "Epoch 13/30\n",
            "22/22 [==============================] - 5s 228ms/step - loss: 0.0444 - accuracy: 0.9774 - val_loss: 0.5090 - val_accuracy: 0.8191\n",
            "Epoch 14/30\n",
            "22/22 [==============================] - 5s 224ms/step - loss: 0.0377 - accuracy: 0.9810 - val_loss: 0.5247 - val_accuracy: 0.8281\n",
            "Epoch 15/30\n",
            "22/22 [==============================] - 5s 223ms/step - loss: 0.0354 - accuracy: 0.9819 - val_loss: 0.5416 - val_accuracy: 0.8168\n",
            "Epoch 16/30\n",
            "22/22 [==============================] - 5s 231ms/step - loss: 0.0290 - accuracy: 0.9860 - val_loss: 0.5716 - val_accuracy: 0.8183\n",
            "Epoch 17/30\n",
            "22/22 [==============================] - 5s 225ms/step - loss: 0.0240 - accuracy: 0.9891 - val_loss: 0.5928 - val_accuracy: 0.8183\n",
            "Epoch 18/30\n",
            "22/22 [==============================] - 5s 224ms/step - loss: 0.0240 - accuracy: 0.9875 - val_loss: 0.5722 - val_accuracy: 0.8198\n",
            "Epoch 19/30\n",
            "22/22 [==============================] - 5s 231ms/step - loss: 0.0200 - accuracy: 0.9901 - val_loss: 0.6190 - val_accuracy: 0.8236\n",
            "Epoch 20/30\n",
            "22/22 [==============================] - 5s 225ms/step - loss: 0.0194 - accuracy: 0.9898 - val_loss: 0.6330 - val_accuracy: 0.8123\n",
            "Epoch 21/30\n",
            "22/22 [==============================] - 5s 224ms/step - loss: 0.0181 - accuracy: 0.9910 - val_loss: 0.6472 - val_accuracy: 0.8183\n",
            "Epoch 22/30\n",
            "22/22 [==============================] - 5s 232ms/step - loss: 0.0170 - accuracy: 0.9914 - val_loss: 0.6352 - val_accuracy: 0.8266\n",
            "Epoch 23/30\n",
            "22/22 [==============================] - 5s 227ms/step - loss: 0.0153 - accuracy: 0.9930 - val_loss: 0.6719 - val_accuracy: 0.8236\n",
            "Epoch 24/30\n",
            "22/22 [==============================] - 5s 224ms/step - loss: 0.0142 - accuracy: 0.9930 - val_loss: 0.6549 - val_accuracy: 0.8206\n",
            "Epoch 25/30\n",
            "22/22 [==============================] - 5s 233ms/step - loss: 0.0172 - accuracy: 0.9918 - val_loss: 0.6430 - val_accuracy: 0.8146\n",
            "Epoch 26/30\n",
            "22/22 [==============================] - 5s 223ms/step - loss: 0.0109 - accuracy: 0.9952 - val_loss: 0.6584 - val_accuracy: 0.8243\n",
            "Epoch 27/30\n",
            "22/22 [==============================] - 5s 223ms/step - loss: 0.0128 - accuracy: 0.9937 - val_loss: 0.7020 - val_accuracy: 0.8123\n",
            "Epoch 28/30\n",
            "22/22 [==============================] - 5s 226ms/step - loss: 0.0137 - accuracy: 0.9936 - val_loss: 0.7012 - val_accuracy: 0.8131\n",
            "Epoch 29/30\n",
            "22/22 [==============================] - 5s 224ms/step - loss: 0.0130 - accuracy: 0.9939 - val_loss: 0.7003 - val_accuracy: 0.8161\n",
            "Epoch 30/30\n",
            "22/22 [==============================] - 5s 227ms/step - loss: 0.0085 - accuracy: 0.9957 - val_loss: 0.7021 - val_accuracy: 0.8251\n"
          ]
        }
      ],
      "source": [
        "\n",
        "history = model2.fit([x_train_int_np,x_train_masks_np],\n",
        "                    y_train,\n",
        "                    epochs=30,\n",
        "                    batch_size=512,\n",
        "                    validation_data=([x_dev_int_np,x_dev_masks_np], y_dev),\n",
        "                    verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "rs0_vvG6UQtv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ba56eca-4bbc-48ba-b11c-6657590d7c36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42/42 [==============================] - 8s 90ms/step - loss: 0.6486 - accuracy: 0.8301\n",
            "[0.6485996246337891, 0.830089807510376]\n"
          ]
        }
      ],
      "source": [
        "results = model2.evaluate([x_test_int_np,x_test_masks_np], y_test)\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awOphcCnhEwv"
      },
      "source": [
        "## Model 3: CNN or LSTM with BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5codSzohQ_9"
      },
      "source": [
        "Please follow the architecture for model2 to construct a CNN or an LSTM model on the top of BERT. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "JMiiWhW4hPRA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25135399-7afd-479c-cda9-0fef01802ab0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.96.80.66:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n",
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_transform', 'vocab_projector', 'activation_13', 'vocab_layer_norm']\n",
            "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "def create_bag_of_words_BERT():\n",
        "  # your code goes here\n",
        "  input_ids_in = tf.keras.layers.Input(shape=(128,), name='input_token', dtype='int32')\n",
        "  input_masks_in = tf.keras.layers.Input(shape=(128,), name='masked_token', dtype='int32')\n",
        "  bert_model = get_BERT_layer()\n",
        "  bert_layer = bert_model(input_ids_in, input_masks_in)\n",
        "  lstm_layer = LSTM(100, return_sequences=False)(bert_layer.last_hidden_state)\n",
        "  label = Dense(3, activation='sigmoid')(lstm_layer)\n",
        "  return Model(inputs=[input_ids_in,input_masks_in], outputs=[label],name='Model2_BERT')\n",
        "\n",
        "use_tpu = True\n",
        "if use_tpu:\n",
        "  # Create distribution strategy\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "  tf.config.experimental_connect_to_cluster(tpu)\n",
        "  tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "  strategy = tf.distribute.TPUStrategy(tpu)\n",
        "\n",
        "  # Create model\n",
        "  with strategy.scope():\n",
        "    model3 = create_bag_of_words_BERT()\n",
        "    optimizer3 = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
        "    model3.compile(optimizer=optimizer3, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "else:\n",
        "  model3 = create_bag_of_words_BERT()\n",
        "  model3.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model3.summary() "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcp7R1035ozX",
        "outputId": "23a15daf-92e7-4d75-c5bf-17edcc8cef7b"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Model2_BERT\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_token (InputLayer)       [(None, 128)]        0           []                               \n",
            "                                                                                                  \n",
            " masked_token (InputLayer)      [(None, 128)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_distil_bert_model_8 (TFDist  TFBaseModelOutput(l  66362880   ['input_token[0][0]',            \n",
            " ilBertModel)                   ast_hidden_state=(N               'masked_token[0][0]']           \n",
            "                                one, 128, 768),                                                   \n",
            "                                 hidden_states=None                                               \n",
            "                                , attentions=None)                                                \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  (None, 100)          347600      ['tf_distil_bert_model_8[0][0]'] \n",
            "                                                                                                  \n",
            " dense_7 (Dense)                (None, 3)            303         ['lstm_1[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 66,710,783\n",
            "Trainable params: 66,710,783\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "c9HmJNzNpIEM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45c972b0-c286-4345-85c7-e852af624347"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "22/22 [==============================] - 112s 3s/step - loss: 0.5982 - accuracy: 0.4706 - val_loss: 0.5499 - val_accuracy: 0.5255\n",
            "Epoch 2/30\n",
            "22/22 [==============================] - 7s 299ms/step - loss: 0.4945 - accuracy: 0.6168 - val_loss: 0.4347 - val_accuracy: 0.6982\n",
            "Epoch 3/30\n",
            "22/22 [==============================] - 6s 293ms/step - loss: 0.3853 - accuracy: 0.7328 - val_loss: 0.3442 - val_accuracy: 0.7643\n",
            "Epoch 4/30\n",
            "22/22 [==============================] - 6s 295ms/step - loss: 0.3030 - accuracy: 0.8042 - val_loss: 0.3127 - val_accuracy: 0.8033\n",
            "Epoch 5/30\n",
            "22/22 [==============================] - 6s 294ms/step - loss: 0.2552 - accuracy: 0.8426 - val_loss: 0.3056 - val_accuracy: 0.8048\n",
            "Epoch 6/30\n",
            "22/22 [==============================] - 6s 292ms/step - loss: 0.2168 - accuracy: 0.8728 - val_loss: 0.3142 - val_accuracy: 0.8093\n",
            "Epoch 7/30\n",
            "22/22 [==============================] - 7s 297ms/step - loss: 0.1774 - accuracy: 0.8993 - val_loss: 0.3159 - val_accuracy: 0.8153\n",
            "Epoch 8/30\n",
            "22/22 [==============================] - 6s 292ms/step - loss: 0.1521 - accuracy: 0.9174 - val_loss: 0.3344 - val_accuracy: 0.8191\n",
            "Epoch 9/30\n",
            "22/22 [==============================] - 7s 297ms/step - loss: 0.1268 - accuracy: 0.9333 - val_loss: 0.3477 - val_accuracy: 0.8161\n",
            "Epoch 10/30\n",
            "22/22 [==============================] - 6s 292ms/step - loss: 0.1056 - accuracy: 0.9457 - val_loss: 0.3581 - val_accuracy: 0.8206\n",
            "Epoch 11/30\n",
            "22/22 [==============================] - 7s 301ms/step - loss: 0.0856 - accuracy: 0.9583 - val_loss: 0.3933 - val_accuracy: 0.8146\n",
            "Epoch 12/30\n",
            "22/22 [==============================] - 6s 292ms/step - loss: 0.0748 - accuracy: 0.9638 - val_loss: 0.3890 - val_accuracy: 0.8213\n",
            "Epoch 13/30\n",
            "22/22 [==============================] - 7s 302ms/step - loss: 0.0683 - accuracy: 0.9675 - val_loss: 0.4068 - val_accuracy: 0.8206\n",
            "Epoch 14/30\n",
            "22/22 [==============================] - 6s 292ms/step - loss: 0.0545 - accuracy: 0.9766 - val_loss: 0.4321 - val_accuracy: 0.8183\n",
            "Epoch 15/30\n",
            "22/22 [==============================] - 7s 299ms/step - loss: 0.0486 - accuracy: 0.9785 - val_loss: 0.4406 - val_accuracy: 0.8221\n",
            "Epoch 16/30\n",
            "22/22 [==============================] - 6s 293ms/step - loss: 0.0456 - accuracy: 0.9800 - val_loss: 0.4427 - val_accuracy: 0.8191\n",
            "Epoch 17/30\n",
            "22/22 [==============================] - 6s 296ms/step - loss: 0.0408 - accuracy: 0.9818 - val_loss: 0.4413 - val_accuracy: 0.8183\n",
            "Epoch 18/30\n",
            "22/22 [==============================] - 6s 293ms/step - loss: 0.0390 - accuracy: 0.9840 - val_loss: 0.4533 - val_accuracy: 0.8183\n",
            "Epoch 19/30\n",
            "22/22 [==============================] - 6s 293ms/step - loss: 0.0343 - accuracy: 0.9861 - val_loss: 0.4641 - val_accuracy: 0.8183\n",
            "Epoch 20/30\n",
            "22/22 [==============================] - 6s 294ms/step - loss: 0.0306 - accuracy: 0.9867 - val_loss: 0.4761 - val_accuracy: 0.8191\n",
            "Epoch 21/30\n",
            "22/22 [==============================] - 6s 292ms/step - loss: 0.0336 - accuracy: 0.9854 - val_loss: 0.4612 - val_accuracy: 0.8213\n",
            "Epoch 22/30\n",
            "22/22 [==============================] - 6s 293ms/step - loss: 0.0261 - accuracy: 0.9894 - val_loss: 0.4709 - val_accuracy: 0.8258\n",
            "Epoch 23/30\n",
            "22/22 [==============================] - 6s 292ms/step - loss: 0.0240 - accuracy: 0.9911 - val_loss: 0.4929 - val_accuracy: 0.8183\n",
            "Epoch 24/30\n",
            "22/22 [==============================] - 7s 303ms/step - loss: 0.0226 - accuracy: 0.9924 - val_loss: 0.4874 - val_accuracy: 0.8221\n",
            "Epoch 25/30\n",
            "22/22 [==============================] - 6s 293ms/step - loss: 0.0224 - accuracy: 0.9909 - val_loss: 0.4956 - val_accuracy: 0.8168\n",
            "Epoch 26/30\n",
            "22/22 [==============================] - 7s 302ms/step - loss: 0.0265 - accuracy: 0.9898 - val_loss: 0.4824 - val_accuracy: 0.8281\n",
            "Epoch 27/30\n",
            "22/22 [==============================] - 6s 293ms/step - loss: 0.0249 - accuracy: 0.9897 - val_loss: 0.4829 - val_accuracy: 0.8266\n",
            "Epoch 28/30\n",
            "22/22 [==============================] - 7s 302ms/step - loss: 0.0248 - accuracy: 0.9899 - val_loss: 0.4754 - val_accuracy: 0.8288\n",
            "Epoch 29/30\n",
            "22/22 [==============================] - 6s 292ms/step - loss: 0.0219 - accuracy: 0.9916 - val_loss: 0.5256 - val_accuracy: 0.8093\n",
            "Epoch 30/30\n",
            "22/22 [==============================] - 7s 300ms/step - loss: 0.0190 - accuracy: 0.9925 - val_loss: 0.5133 - val_accuracy: 0.8251\n"
          ]
        }
      ],
      "source": [
        "\n",
        "history = model3.fit([x_train_int_np,x_train_masks_np],\n",
        "                    y_train,\n",
        "                    epochs=30,\n",
        "                    batch_size=512,\n",
        "                    validation_data=([x_dev_int_np,x_dev_masks_np], y_dev),\n",
        "                    verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "W7TXLjQhpY--",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ded2738-21ad-4e76-92df-2a086d9088a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42/42 [==============================] - 9s 110ms/step - loss: 0.5127 - accuracy: 0.8234\n",
            "[0.5126556754112244, 0.8233532905578613]\n"
          ]
        }
      ],
      "source": [
        "results = model3.evaluate([x_test_int_np,x_test_masks_np], y_test)\n",
        "print(results)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [
        "UqvUGIwwGJqu",
        "vdZ4nl08vp9A",
        "awOphcCnhEwv"
      ],
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c4a981cc30014b77b7670346539ee0ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2b34a4df965c46c09ed3ed63cb29eb43",
              "IPY_MODEL_e77e076a14df419baeb0c9e0155c4a6b",
              "IPY_MODEL_3fb4ecd439dd4e4c9fed9b52f0376d53"
            ],
            "layout": "IPY_MODEL_ff7a7a473af74d1d8af73a1ef839f662"
          }
        },
        "2b34a4df965c46c09ed3ed63cb29eb43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8318f933cbf34c128cbb411a27bc9d11",
            "placeholder": "​",
            "style": "IPY_MODEL_2e99f1b72bdf45cfb1b689b1484a3405",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "e77e076a14df419baeb0c9e0155c4a6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67779d7c0a1e45cab91a4dc25dc1e553",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cf17db91a185485e804d7fbfd5b6d9ff",
            "value": 231508
          }
        },
        "3fb4ecd439dd4e4c9fed9b52f0376d53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe3f5a9927d64c96b79c0e0a52142e19",
            "placeholder": "​",
            "style": "IPY_MODEL_ba04c0fdcfbe4f69ac33bcd5984facdb",
            "value": " 232k/232k [00:00&lt;00:00, 1.83MB/s]"
          }
        },
        "ff7a7a473af74d1d8af73a1ef839f662": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8318f933cbf34c128cbb411a27bc9d11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e99f1b72bdf45cfb1b689b1484a3405": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "67779d7c0a1e45cab91a4dc25dc1e553": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf17db91a185485e804d7fbfd5b6d9ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fe3f5a9927d64c96b79c0e0a52142e19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba04c0fdcfbe4f69ac33bcd5984facdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ee989fd1ad4c4901bfc7f2cf51b3a79a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b21aab5dc9d0413a9a6b04969c1a8111",
              "IPY_MODEL_3727581133c345c597faaaa539d7256f",
              "IPY_MODEL_c3c6e0f6d9c34ae882d9276dfd491809"
            ],
            "layout": "IPY_MODEL_949d9af37dd34b7e8b9aecc1490bc24e"
          }
        },
        "b21aab5dc9d0413a9a6b04969c1a8111": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bfb8dc21c419405383c951159aeb5e7d",
            "placeholder": "​",
            "style": "IPY_MODEL_0d25d62b438e4583bdd27a6c0d1f3c28",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "3727581133c345c597faaaa539d7256f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e8834093d0045d5af649e4a6a89be4a",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_280860a835d8443e9159c344caf437f0",
            "value": 28
          }
        },
        "c3c6e0f6d9c34ae882d9276dfd491809": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a21067d914d41cfa8c375d826b17a3e",
            "placeholder": "​",
            "style": "IPY_MODEL_ee72902f437c487ab43cde98d224b421",
            "value": " 28.0/28.0 [00:00&lt;00:00, 851B/s]"
          }
        },
        "949d9af37dd34b7e8b9aecc1490bc24e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfb8dc21c419405383c951159aeb5e7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d25d62b438e4583bdd27a6c0d1f3c28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e8834093d0045d5af649e4a6a89be4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "280860a835d8443e9159c344caf437f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0a21067d914d41cfa8c375d826b17a3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee72902f437c487ab43cde98d224b421": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a70f83babaa04f65b676345be9f4789b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6756452aa3a14edeaa6ada158d23ac27",
              "IPY_MODEL_524d73066ffe4dbaacd46f123dadb63b",
              "IPY_MODEL_95af3c619ac54ca2986d94611a7c5b36"
            ],
            "layout": "IPY_MODEL_ea3fed974beb4ea4bd59327a65f4d7ab"
          }
        },
        "6756452aa3a14edeaa6ada158d23ac27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c85a8f600db46f3b27b90f99f16eada",
            "placeholder": "​",
            "style": "IPY_MODEL_956ca8a19d20415c8880107dbd3732e1",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "524d73066ffe4dbaacd46f123dadb63b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1d7ecc1a35f4b80b98c4dba3c34091e",
            "max": 483,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ad7a2de770ef440e93f1577e7a6a5cdf",
            "value": 483
          }
        },
        "95af3c619ac54ca2986d94611a7c5b36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_724596496b144538aed56a8fea24593e",
            "placeholder": "​",
            "style": "IPY_MODEL_fcda7f10fe8e4b73991e8eb70c52d009",
            "value": " 483/483 [00:00&lt;00:00, 13.7kB/s]"
          }
        },
        "ea3fed974beb4ea4bd59327a65f4d7ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c85a8f600db46f3b27b90f99f16eada": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "956ca8a19d20415c8880107dbd3732e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b1d7ecc1a35f4b80b98c4dba3c34091e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad7a2de770ef440e93f1577e7a6a5cdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "724596496b144538aed56a8fea24593e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fcda7f10fe8e4b73991e8eb70c52d009": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}